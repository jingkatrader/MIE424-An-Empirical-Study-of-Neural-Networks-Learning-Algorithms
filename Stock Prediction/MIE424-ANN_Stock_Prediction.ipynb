{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MIE424-ANN_Stock_Prediction.ipynb","provenance":[{"file_id":"1Bu5ObrA-D4K367v3MKk6jxIkAPLSjysP","timestamp":1617841526104}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"6i4zcLXhbElF"},"source":["# Importing Tensorflow"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"avq2wtTcl_24","executionInfo":{"status":"ok","timestamp":1618259766628,"user_tz":240,"elapsed":4212,"user":{"displayName":"Jingkai Xu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg2sWxfWEtas0OHVeRAKACfv2J-WqEkZOHE68L3EA=s64","userId":"14485307633456209780"}},"outputId":"f2bfe7f7-a87a-48c9-db02-f86f0279a96f"},"source":["\n","!pip install tensorflow\n","# MUST restart runtime after running this "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.4.1)\n","Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n","Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.4.0)\n","Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n","Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.19.5)\n","Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.36.2)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.12.4)\n","Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.3.3)\n","Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.4.1)\n","Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.10.0)\n","Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.7.4.3)\n","Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n","Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12.1)\n","Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n","Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.12.0)\n","Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.32.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.9.2->tensorflow) (54.2.0)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (2.23.0)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (1.28.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (3.3.4)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (1.8.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (0.4.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.12.5)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.7.2)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.2.1)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.8.1)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (1.3.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.4.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.4.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (3.1.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8DdZRyN-b2_O","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618259768532,"user_tz":240,"elapsed":3632,"user":{"displayName":"Jingkai Xu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg2sWxfWEtas0OHVeRAKACfv2J-WqEkZOHE68L3EA=s64","userId":"14485307633456209780"}},"outputId":"54eef4d3-2e5a-4751-bb02-688c90b952bf"},"source":["# checking tensorflow version\n","import tensorflow as tf\n","tf.random.set_seed(424)\n","# from tensorflow.contrib.tensor_forest import tensor_forest\n","# from tensorflow.python.ops import resources\n","print(tf.__version__)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2.4.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CBbB049dcbV8","executionInfo":{"status":"ok","timestamp":1619720700827,"user_tz":240,"elapsed":3071,"user":{"displayName":"Jingkai Xu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg2sWxfWEtas0OHVeRAKACfv2J-WqEkZOHE68L3EA=s64","userId":"14485307633456209780"}}},"source":["# Import libraries\n","from __future__ import print_function\n","import numpy as np\n","import pandas as pd\n","import sklearn\n","from sklearn.model_selection import train_test_split\n","\n","# Ignore all GPUs, tf random forest does not benefit from it.\n","import os\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n","\n","# Binary Classification with Sonar Dataset: Baseline\n","from pandas import read_csv\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.wrappers.scikit_learn import KerasClassifier\n","from sklearn.model_selection import cross_val_score\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import StratifiedKFold\n","import keras\n","import time"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_Ky-xdFObhWm","executionInfo":{"status":"ok","timestamp":1619720725818,"user_tz":240,"elapsed":28057,"user":{"displayName":"Jingkai Xu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg2sWxfWEtas0OHVeRAKACfv2J-WqEkZOHE68L3EA=s64","userId":"14485307633456209780"}},"outputId":"6fd4e1f9-bdb5-44fc-a7fb-249d51261efd"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4pG6IqxwbvPC","executionInfo":{"status":"ok","timestamp":1619720940792,"user_tz":240,"elapsed":223,"user":{"displayName":"Jingkai Xu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg2sWxfWEtas0OHVeRAKACfv2J-WqEkZOHE68L3EA=s64","userId":"14485307633456209780"}}},"source":["# normalize [-1,1]\n","def normalize(df):\n","    result = df.copy()\n","    for feature_name in df.columns:\n","        max_value = df[feature_name].max()\n","        min_value = df[feature_name].min()\n","        result[feature_name] = 2*((df[feature_name] - min_value) / (max_value - min_value))-1\n","    return result\n","\n","# normalize [0,1] - not using \n","def normalize01(df):\n","    result = df.copy()\n","    for feature_name in df.columns:\n","        max_value = df[feature_name].max()\n","        min_value = df[feature_name].min()\n","        result[feature_name] = 2*((df[feature_name] - min_value) / (max_value - min_value))-1\n","    return result"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"wWzDkfT6dGqR","executionInfo":{"status":"ok","timestamp":1619720730675,"user_tz":240,"elapsed":4578,"user":{"displayName":"Jingkai Xu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg2sWxfWEtas0OHVeRAKACfv2J-WqEkZOHE68L3EA=s64","userId":"14485307633456209780"}}},"source":["sheet_name = ['BSE_Sensex', 'NIFTY_50', 'Reliance', 'Infosys']\n","BSE_Sensex_feature = pd.read_excel(\"/content/gdrive/My Drive/MIE424-Project/data_feature_more.xlsx\",sheet_name=sheet_name[0])\n","# NIFTY_50_feature = pd.read_excel(\"/content/gdrive/My Drive/MIE424-Project/data_feature_more.xlsx\",sheet_name=sheet_name[1])\n","# Reliance_feature = pd.read_excel(\"/content/gdrive/My Drive/MIE424-Project/data_feature_more.xlsx\",sheet_name=sheet_name[2])\n","# Infosys_feature = pd.read_excel(\"/content/gdrive/My Drive/MIE424-Project/data_feature_more.xlsx\",sheet_name=sheet_name[3])"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fUO9LGyrRtly"},"source":["# **ANN**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":406},"id":"LvV922n8G9YS","executionInfo":{"status":"ok","timestamp":1619720736970,"user_tz":240,"elapsed":375,"user":{"displayName":"Jingkai Xu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg2sWxfWEtas0OHVeRAKACfv2J-WqEkZOHE68L3EA=s64","userId":"14485307633456209780"}},"outputId":"c4dbebff-8238-4a4b-8c61-9acfa45d5e90"},"source":["BSE_Sensex_feature"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Date</th>\n","      <th>Close</th>\n","      <th>MA_10</th>\n","      <th>WMA_10</th>\n","      <th>Momentum_10</th>\n","      <th>SO%k</th>\n","      <th>SO%d_10</th>\n","      <th>RSI_10</th>\n","      <th>MACD</th>\n","      <th>LW_R</th>\n","      <th>AD_R</th>\n","      <th>CCI_10</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1991-03-14</td>\n","      <td>1196.48</td>\n","      <td>1196.133</td>\n","      <td>1448.361111</td>\n","      <td>-17.79</td>\n","      <td>0.198185</td>\n","      <td>0.612414</td>\n","      <td>-613.827993</td>\n","      <td>36.722136</td>\n","      <td>-80.181530</td>\n","      <td>0.798127</td>\n","      <td>-56.850448</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1991-03-15</td>\n","      <td>1206.75</td>\n","      <td>1195.261</td>\n","      <td>1448.438222</td>\n","      <td>-8.72</td>\n","      <td>0.518946</td>\n","      <td>0.570987</td>\n","      <td>-1356.307339</td>\n","      <td>35.104788</td>\n","      <td>-48.105393</td>\n","      <td>0.792338</td>\n","      <td>-23.627201</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1991-03-18</td>\n","      <td>1171.08</td>\n","      <td>1193.781</td>\n","      <td>1450.991333</td>\n","      <td>-14.80</td>\n","      <td>0.609447</td>\n","      <td>0.531932</td>\n","      <td>-758.040541</td>\n","      <td>33.875538</td>\n","      <td>-39.055340</td>\n","      <td>1.327092</td>\n","      <td>56.462264</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1991-03-20</td>\n","      <td>1171.92</td>\n","      <td>1188.848</td>\n","      <td>1445.946667</td>\n","      <td>-49.33</td>\n","      <td>0.295118</td>\n","      <td>0.473500</td>\n","      <td>-227.427529</td>\n","      <td>32.335611</td>\n","      <td>-70.488192</td>\n","      <td>-1.097561</td>\n","      <td>-26.504612</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1991-03-21</td>\n","      <td>1165.20</td>\n","      <td>1183.496</td>\n","      <td>1442.184889</td>\n","      <td>-53.52</td>\n","      <td>0.302520</td>\n","      <td>0.414585</td>\n","      <td>-201.793722</td>\n","      <td>30.627530</td>\n","      <td>-69.747973</td>\n","      <td>0.849635</td>\n","      <td>-25.001604</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7233</th>\n","      <td>2020-12-24</td>\n","      <td>46973.54</td>\n","      <td>46309.784</td>\n","      <td>56628.973778</td>\n","      <td>340.68</td>\n","      <td>0.713257</td>\n","      <td>0.814947</td>\n","      <td>555.075144</td>\n","      <td>1021.280189</td>\n","      <td>-28.674254</td>\n","      <td>0.824835</td>\n","      <td>8.552392</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7234</th>\n","      <td>2020-12-28</td>\n","      <td>47353.75</td>\n","      <td>46411.150</td>\n","      <td>56776.475111</td>\n","      <td>1013.66</td>\n","      <td>0.961479</td>\n","      <td>0.819005</td>\n","      <td>238.777302</td>\n","      <td>1001.588984</td>\n","      <td>-3.852087</td>\n","      <td>1.184377</td>\n","      <td>95.661306</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7235</th>\n","      <td>2020-12-29</td>\n","      <td>47613.08</td>\n","      <td>46536.624</td>\n","      <td>56985.941778</td>\n","      <td>1254.74</td>\n","      <td>0.978672</td>\n","      <td>0.825973</td>\n","      <td>212.113266</td>\n","      <td>990.237684</td>\n","      <td>-2.132757</td>\n","      <td>1.675874</td>\n","      <td>131.145622</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7236</th>\n","      <td>2020-12-30</td>\n","      <td>47746.22</td>\n","      <td>46672.586</td>\n","      <td>57225.154222</td>\n","      <td>1359.62</td>\n","      <td>0.963650</td>\n","      <td>0.827654</td>\n","      <td>203.464939</td>\n","      <td>986.494748</td>\n","      <td>-3.635002</td>\n","      <td>1.023111</td>\n","      <td>132.583835</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7237</th>\n","      <td>2020-12-31</td>\n","      <td>47751.33</td>\n","      <td>46820.891</td>\n","      <td>57463.739556</td>\n","      <td>1483.05</td>\n","      <td>0.978636</td>\n","      <td>0.830517</td>\n","      <td>194.853848</td>\n","      <td>987.698264</td>\n","      <td>-2.136392</td>\n","      <td>0.433313</td>\n","      <td>115.503452</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7238 rows × 13 columns</p>\n","</div>"],"text/plain":["           Date     Close      MA_10  ...      AD_R      CCI_10  label\n","0    1991-03-14   1196.48   1196.133  ...  0.798127  -56.850448      1\n","1    1991-03-15   1206.75   1195.261  ...  0.792338  -23.627201      1\n","2    1991-03-18   1171.08   1193.781  ...  1.327092   56.462264      0\n","3    1991-03-20   1171.92   1188.848  ... -1.097561  -26.504612      1\n","4    1991-03-21   1165.20   1183.496  ...  0.849635  -25.001604      0\n","...         ...       ...        ...  ...       ...         ...    ...\n","7233 2020-12-24  46973.54  46309.784  ...  0.824835    8.552392      1\n","7234 2020-12-28  47353.75  46411.150  ...  1.184377   95.661306      1\n","7235 2020-12-29  47613.08  46536.624  ...  1.675874  131.145622      1\n","7236 2020-12-30  47746.22  46672.586  ...  1.023111  132.583835      1\n","7237 2020-12-31  47751.33  46820.891  ...  0.433313  115.503452      1\n","\n","[7238 rows x 13 columns]"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"2ABWYFxxCxL6"},"source":["# Data preparation"]},{"cell_type":"code","metadata":{"id":"hGDQH-sQSIig","executionInfo":{"status":"ok","timestamp":1619720943013,"user_tz":240,"elapsed":237,"user":{"displayName":"Jingkai Xu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg2sWxfWEtas0OHVeRAKACfv2J-WqEkZOHE68L3EA=s64","userId":"14485307633456209780"}}},"source":["from pandas import read_csv\n","# from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.wrappers.scikit_learn import KerasClassifier\n","from sklearn.model_selection import cross_val_score\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import StratifiedKFold\n","data = BSE_Sensex_feature.dropna() # DROPNA\n","\n","del data[\"Close\"]\n","\n","#Extract feature and target np arrays (inputs for placeholders)\n","input_x = normalize(data.iloc[:, 1:-1]).values  # NORMALIZE \n","input_y = data.iloc[:, -1:].values\n","\n","# Splitting the dataset into the Training set and Test set\n","\n","#X_train, X_test, y_train, y_test = train_test_split(input_x, input_y, test_size = 0.25, random_state = 0)\n"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"hIBxUZcnJ4TG","executionInfo":{"status":"ok","timestamp":1619720943225,"user_tz":240,"elapsed":228,"user":{"displayName":"Jingkai Xu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg2sWxfWEtas0OHVeRAKACfv2J-WqEkZOHE68L3EA=s64","userId":"14485307633456209780"}}},"source":["# Construct a time series input features\n","# as defined by how many prior days of input features to be used to predict today's stock movement\n","num_days = 3\n","new_input_x = []\n","for i in range (num_days, input_x.shape[0]+1):\n","    new_input_x.append(input_x[i-num_days: i, :].flatten())\n","new_input_x = np.array(new_input_x)\n","\n","new_input_y = input_y[num_days-1:]\n","\n","# X_train = new_input_x[:int(new_input_x.shape[0]*0.8), :]\n","# y_train = new_input_y[:int(new_input_y.shape[0]*0.8), :]\n","# X_test = new_input_x[int(new_input_x.shape[0]*0.8):, :]\n","# y_test = new_input_y[int(new_input_y.shape[0]*0.8):, :]\n","\n","# Splitting the dataset into the Training set and Test set\n","X_train, X_test, y_train, y_test = train_test_split(new_input_x, new_input_y, test_size = 0.2, random_state = 424)\n"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pmcorw1x8FGz","executionInfo":{"status":"ok","timestamp":1619721749931,"user_tz":240,"elapsed":271,"user":{"displayName":"Jingkai Xu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg2sWxfWEtas0OHVeRAKACfv2J-WqEkZOHE68L3EA=s64","userId":"14485307633456209780"}},"outputId":"22c37490-cca2-4b56-df5e-cb0041e7b747"},"source":["new_input_x.shape"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(7236, 30)"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RCqaze6h41y3","executionInfo":{"status":"ok","timestamp":1619720984094,"user_tz":240,"elapsed":552,"user":{"displayName":"Jingkai Xu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg2sWxfWEtas0OHVeRAKACfv2J-WqEkZOHE68L3EA=s64","userId":"14485307633456209780"}},"outputId":"183de1d3-3199-47b3-b224-ab30dfe8812d"},"source":["print(\"percentage of price UP in FULL DATASET: {}\".format((BSE_Sensex_feature['label']==1).sum()/BSE_Sensex_feature.shape[0]))\n","print(\"percentage of price UP in TRAINING DATAASET: {}\".format((y_train==1).sum()/y_train.shape[0]))\n","print(\"percentage of price UP in TEST DATAASET: {}\".format((y_test==1).sum()/y_test.shape[0]))"],"execution_count":23,"outputs":[{"output_type":"stream","text":["percentage of price UP in FULL DATASET: 0.5316385741917656\n","percentage of price UP in TRAINING DATAASET: 0.5295438838977194\n","percentage of price UP in TEST DATAASET: 0.539364640883978\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0tunvoSck6Hy"},"source":["# Adam"]},{"cell_type":"markdown","metadata":{"id":"_mIXn1Aa8BtD"},"source":["## batch 32"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"52ghrhbAzmI3","executionInfo":{"status":"ok","timestamp":1618259941335,"user_tz":240,"elapsed":45926,"user":{"displayName":"Jingkai Xu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg2sWxfWEtas0OHVeRAKACfv2J-WqEkZOHE68L3EA=s64","userId":"14485307633456209780"}},"outputId":"1a75b7db-024a-4aa4-ae9b-1d69f8f6c80e"},"source":["%%time\n","tf.random.set_seed(424)\n","# define the keras model\n","model = Sequential()\n","model.add(Dense(60, input_dim=10*num_days, activation='relu'))\n","model.add(Dense(128, activation='relu'))\n","# model.add(Dense(128, activation='relu'))\n","# model.add(Dense(20, activation='relu'))\n","# model.add(Dense(1, activation='sigmoid'))\n","\n","model.add(Dense(128, activation='relu'))\n","model.add(Dense(20, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","opt = keras.optimizers.Adam(learning_rate=0.1)\n","\n","model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n","model.fit(X_train, y_train, epochs=100,validation_split=0.1)\n","# mlp__validation_split=0.3"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","163/163 [==============================] - 1s 4ms/step - loss: 1.2101 - accuracy: 0.5177 - val_loss: 0.6892 - val_accuracy: 0.5630\n","Epoch 2/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6924 - accuracy: 0.5151 - val_loss: 0.7044 - val_accuracy: 0.4370\n","Epoch 3/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.5131 - val_loss: 0.6946 - val_accuracy: 0.4370\n","Epoch 4/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.5175 - val_loss: 0.6852 - val_accuracy: 0.5630\n","Epoch 5/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6930 - accuracy: 0.5256 - val_loss: 0.6852 - val_accuracy: 0.5630\n","Epoch 6/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6940 - accuracy: 0.5186 - val_loss: 0.6884 - val_accuracy: 0.5630\n","Epoch 7/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6940 - accuracy: 0.5235 - val_loss: 0.6880 - val_accuracy: 0.5630\n","Epoch 8/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.5250 - val_loss: 0.6907 - val_accuracy: 0.5630\n","Epoch 9/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6941 - accuracy: 0.5096 - val_loss: 0.6875 - val_accuracy: 0.5630\n","Epoch 10/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6946 - accuracy: 0.5116 - val_loss: 0.6852 - val_accuracy: 0.5630\n","Epoch 11/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5228 - val_loss: 0.6869 - val_accuracy: 0.5630\n","Epoch 12/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6956 - accuracy: 0.5033 - val_loss: 0.6853 - val_accuracy: 0.5630\n","Epoch 13/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6947 - accuracy: 0.5039 - val_loss: 0.6920 - val_accuracy: 0.5630\n","Epoch 14/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6941 - accuracy: 0.5193 - val_loss: 0.6931 - val_accuracy: 0.5630\n","Epoch 15/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.5070 - val_loss: 0.6871 - val_accuracy: 0.5630\n","Epoch 16/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6940 - accuracy: 0.5155 - val_loss: 0.6917 - val_accuracy: 0.5630\n","Epoch 17/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6958 - accuracy: 0.5157 - val_loss: 0.6867 - val_accuracy: 0.5630\n","Epoch 18/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6940 - accuracy: 0.5157 - val_loss: 0.6865 - val_accuracy: 0.5630\n","Epoch 19/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6911 - accuracy: 0.5403 - val_loss: 0.6916 - val_accuracy: 0.5630\n","Epoch 20/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.5251 - val_loss: 0.7044 - val_accuracy: 0.4370\n","Epoch 21/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.4995 - val_loss: 0.6969 - val_accuracy: 0.4370\n","Epoch 22/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6938 - accuracy: 0.5081 - val_loss: 0.6888 - val_accuracy: 0.5630\n","Epoch 23/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.5193 - val_loss: 0.6891 - val_accuracy: 0.5630\n","Epoch 24/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6928 - accuracy: 0.5235 - val_loss: 0.6852 - val_accuracy: 0.5630\n","Epoch 25/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5217 - val_loss: 0.6852 - val_accuracy: 0.5630\n","Epoch 26/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.5150 - val_loss: 0.6899 - val_accuracy: 0.5630\n","Epoch 27/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5324 - val_loss: 0.6911 - val_accuracy: 0.5630\n","Epoch 28/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6942 - accuracy: 0.5263 - val_loss: 0.6928 - val_accuracy: 0.5630\n","Epoch 29/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6925 - accuracy: 0.5168 - val_loss: 0.6987 - val_accuracy: 0.4370\n","Epoch 30/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.5119 - val_loss: 0.6852 - val_accuracy: 0.5630\n","Epoch 31/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6916 - accuracy: 0.5279 - val_loss: 0.7047 - val_accuracy: 0.4370\n","Epoch 32/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6950 - accuracy: 0.5054 - val_loss: 0.6930 - val_accuracy: 0.5630\n","Epoch 33/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6938 - accuracy: 0.5110 - val_loss: 0.6863 - val_accuracy: 0.5630\n","Epoch 34/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5179 - val_loss: 0.6916 - val_accuracy: 0.5630\n","Epoch 35/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.5207 - val_loss: 0.6891 - val_accuracy: 0.5630\n","Epoch 36/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6952 - accuracy: 0.5102 - val_loss: 0.6962 - val_accuracy: 0.4370\n","Epoch 37/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6955 - accuracy: 0.5070 - val_loss: 0.6980 - val_accuracy: 0.4370\n","Epoch 38/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6955 - accuracy: 0.5038 - val_loss: 0.6852 - val_accuracy: 0.5630\n","Epoch 39/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6940 - accuracy: 0.5153 - val_loss: 0.6920 - val_accuracy: 0.5630\n","Epoch 40/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6919 - accuracy: 0.5335 - val_loss: 0.7135 - val_accuracy: 0.4370\n","Epoch 41/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6958 - accuracy: 0.4997 - val_loss: 0.6873 - val_accuracy: 0.5630\n","Epoch 42/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6954 - accuracy: 0.5070 - val_loss: 0.6919 - val_accuracy: 0.5630\n","Epoch 43/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6928 - accuracy: 0.5263 - val_loss: 0.6895 - val_accuracy: 0.5630\n","Epoch 44/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6945 - accuracy: 0.4980 - val_loss: 0.6853 - val_accuracy: 0.5630\n","Epoch 45/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6941 - accuracy: 0.5229 - val_loss: 0.6942 - val_accuracy: 0.4370\n","Epoch 46/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6928 - accuracy: 0.5276 - val_loss: 0.6887 - val_accuracy: 0.5630\n","Epoch 47/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5172 - val_loss: 0.6988 - val_accuracy: 0.4370\n","Epoch 48/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5214 - val_loss: 0.6984 - val_accuracy: 0.4370\n","Epoch 49/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6945 - accuracy: 0.5136 - val_loss: 0.6855 - val_accuracy: 0.5630\n","Epoch 50/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6928 - accuracy: 0.5198 - val_loss: 0.6997 - val_accuracy: 0.4370\n","Epoch 51/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5225 - val_loss: 0.6870 - val_accuracy: 0.5630\n","Epoch 52/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6954 - accuracy: 0.5042 - val_loss: 0.6884 - val_accuracy: 0.5630\n","Epoch 53/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6925 - accuracy: 0.5353 - val_loss: 0.6853 - val_accuracy: 0.5630\n","Epoch 54/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6949 - accuracy: 0.5138 - val_loss: 0.6934 - val_accuracy: 0.4370\n","Epoch 55/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6920 - accuracy: 0.5393 - val_loss: 0.7045 - val_accuracy: 0.4370\n","Epoch 56/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6924 - accuracy: 0.5229 - val_loss: 0.6903 - val_accuracy: 0.5630\n","Epoch 57/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.5224 - val_loss: 0.6910 - val_accuracy: 0.5630\n","Epoch 58/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6952 - accuracy: 0.5079 - val_loss: 0.6867 - val_accuracy: 0.5630\n","Epoch 59/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6946 - accuracy: 0.5093 - val_loss: 0.6870 - val_accuracy: 0.5630\n","Epoch 60/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6946 - accuracy: 0.5220 - val_loss: 0.6910 - val_accuracy: 0.5630\n","Epoch 61/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5131 - val_loss: 0.6883 - val_accuracy: 0.5630\n","Epoch 62/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6950 - accuracy: 0.4983 - val_loss: 0.6877 - val_accuracy: 0.5630\n","Epoch 63/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6920 - accuracy: 0.5342 - val_loss: 0.6852 - val_accuracy: 0.5630\n","Epoch 64/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6953 - accuracy: 0.5035 - val_loss: 0.6852 - val_accuracy: 0.5630\n","Epoch 65/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6965 - accuracy: 0.5056 - val_loss: 0.6859 - val_accuracy: 0.5630\n","Epoch 66/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.5188 - val_loss: 0.6973 - val_accuracy: 0.4370\n","Epoch 67/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5115 - val_loss: 0.6878 - val_accuracy: 0.5630\n","Epoch 68/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6930 - accuracy: 0.5297 - val_loss: 0.6861 - val_accuracy: 0.5630\n","Epoch 69/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6948 - accuracy: 0.5207 - val_loss: 0.6960 - val_accuracy: 0.4370\n","Epoch 70/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6944 - accuracy: 0.5128 - val_loss: 0.6933 - val_accuracy: 0.4370\n","Epoch 71/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.5057 - val_loss: 0.6906 - val_accuracy: 0.5630\n","Epoch 72/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6939 - accuracy: 0.5151 - val_loss: 0.6863 - val_accuracy: 0.5630\n","Epoch 73/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6909 - accuracy: 0.5431 - val_loss: 0.6862 - val_accuracy: 0.5630\n","Epoch 74/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6945 - accuracy: 0.5050 - val_loss: 0.6892 - val_accuracy: 0.5630\n","Epoch 75/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5234 - val_loss: 0.7053 - val_accuracy: 0.4370\n","Epoch 76/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6951 - accuracy: 0.5057 - val_loss: 0.6998 - val_accuracy: 0.4370\n","Epoch 77/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6954 - accuracy: 0.4988 - val_loss: 0.6933 - val_accuracy: 0.4370\n","Epoch 78/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5150 - val_loss: 0.6865 - val_accuracy: 0.5630\n","Epoch 79/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.5246 - val_loss: 0.6938 - val_accuracy: 0.4370\n","Epoch 80/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.5209 - val_loss: 0.6897 - val_accuracy: 0.5630\n","Epoch 81/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6940 - accuracy: 0.5160 - val_loss: 0.6872 - val_accuracy: 0.5630\n","Epoch 82/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.5196 - val_loss: 0.6864 - val_accuracy: 0.5630\n","Epoch 83/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.5162 - val_loss: 0.6886 - val_accuracy: 0.5630\n","Epoch 84/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.5148 - val_loss: 0.6929 - val_accuracy: 0.5630\n","Epoch 85/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6967 - accuracy: 0.4910 - val_loss: 0.6999 - val_accuracy: 0.4370\n","Epoch 86/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6947 - accuracy: 0.5016 - val_loss: 0.6875 - val_accuracy: 0.5630\n","Epoch 87/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6930 - accuracy: 0.5192 - val_loss: 0.6935 - val_accuracy: 0.4370\n","Epoch 88/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.5167 - val_loss: 0.6965 - val_accuracy: 0.4370\n","Epoch 89/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6939 - accuracy: 0.4990 - val_loss: 0.6852 - val_accuracy: 0.5630\n","Epoch 90/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6939 - accuracy: 0.5239 - val_loss: 0.6853 - val_accuracy: 0.5630\n","Epoch 91/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6946 - accuracy: 0.5152 - val_loss: 0.6955 - val_accuracy: 0.4370\n","Epoch 92/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6928 - accuracy: 0.5183 - val_loss: 0.7130 - val_accuracy: 0.4370\n","Epoch 93/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6990 - accuracy: 0.5094 - val_loss: 0.6862 - val_accuracy: 0.5630\n","Epoch 94/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6959 - accuracy: 0.4999 - val_loss: 0.6855 - val_accuracy: 0.5630\n","Epoch 95/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6948 - accuracy: 0.5135 - val_loss: 0.6935 - val_accuracy: 0.4370\n","Epoch 96/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6939 - accuracy: 0.4934 - val_loss: 0.6858 - val_accuracy: 0.5630\n","Epoch 97/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.5253 - val_loss: 0.6933 - val_accuracy: 0.4370\n","Epoch 98/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6941 - accuracy: 0.5173 - val_loss: 0.6911 - val_accuracy: 0.5630\n","Epoch 99/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6939 - accuracy: 0.5186 - val_loss: 0.6863 - val_accuracy: 0.5630\n","Epoch 100/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6948 - accuracy: 0.5043 - val_loss: 0.6882 - val_accuracy: 0.5630\n","CPU times: user 51.8 s, sys: 4.91 s, total: 56.7 s\n","Wall time: 45.7 s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4iTW3GuKzoDd","executionInfo":{"status":"ok","timestamp":1618259941822,"user_tz":240,"elapsed":465,"user":{"displayName":"Jingkai Xu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg2sWxfWEtas0OHVeRAKACfv2J-WqEkZOHE68L3EA=s64","userId":"14485307633456209780"}},"outputId":"08776ba0-5d01-451a-ec33-46cafbbab8ef"},"source":["_, accuracy = model.evaluate(X_test, y_test)\n","print('Accuracy: %.2f' % (accuracy*100))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["46/46 [==============================] - 0s 1ms/step - loss: 0.6905 - accuracy: 0.5394\n","Accuracy: 53.94\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"fSx1Mbkz85Ce"},"source":["## batch 64"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yNyJ02D_8wYn","executionInfo":{"status":"ok","timestamp":1618195243990,"user_tz":240,"elapsed":28440,"user":{"displayName":"Jingkai Xu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg2sWxfWEtas0OHVeRAKACfv2J-WqEkZOHE68L3EA=s64","userId":"14485307633456209780"}},"outputId":"815197e2-39cc-4bca-dd44-e986ba9ea7c4"},"source":["%%time\n","tf.random.set_seed(424)\n","# define the keras model\n","model = Sequential()\n","model.add(Dense(60, input_dim=10*num_days, activation='relu'))\n","model.add(Dense(128, activation='relu'))\n","# model.add(Dense(128, activation='relu'))\n","# model.add(Dense(20, activation='relu'))\n","# model.add(Dense(1, activation='sigmoid'))\n","\n","model.add(Dense(128, activation='relu'))\n","model.add(Dense(20, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","opt = keras.optimizers.Adam(learning_rate=0.1)\n","\n","model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n","model.fit(X_train, y_train, epochs=100, batch_size = 64, validation_split=0.1)\n","# mlp__validation_split=0.3"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","82/82 [==============================] - 1s 6ms/step - loss: 3.6060 - accuracy: 0.4932 - val_loss: 0.6903 - val_accuracy: 0.5630\n","Epoch 2/100\n","82/82 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5100 - val_loss: 0.6895 - val_accuracy: 0.5630\n","Epoch 3/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6925 - accuracy: 0.5285 - val_loss: 0.6855 - val_accuracy: 0.5630\n","Epoch 4/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6964 - accuracy: 0.4956 - val_loss: 0.6853 - val_accuracy: 0.5630\n","Epoch 5/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6924 - accuracy: 0.5215 - val_loss: 0.6856 - val_accuracy: 0.5630\n","Epoch 6/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6928 - accuracy: 0.5215 - val_loss: 0.6886 - val_accuracy: 0.5630\n","Epoch 7/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5260 - val_loss: 0.6865 - val_accuracy: 0.5630\n","Epoch 8/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6945 - accuracy: 0.5170 - val_loss: 0.6919 - val_accuracy: 0.5630\n","Epoch 9/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5075 - val_loss: 0.7031 - val_accuracy: 0.4370\n","Epoch 10/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6957 - accuracy: 0.4931 - val_loss: 0.6859 - val_accuracy: 0.5630\n","Epoch 11/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5294 - val_loss: 0.6854 - val_accuracy: 0.5630\n","Epoch 12/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6964 - accuracy: 0.4963 - val_loss: 0.6854 - val_accuracy: 0.5630\n","Epoch 13/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6959 - accuracy: 0.5047 - val_loss: 0.6900 - val_accuracy: 0.5630\n","Epoch 14/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5177 - val_loss: 0.6933 - val_accuracy: 0.4370\n","Epoch 15/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6928 - accuracy: 0.5138 - val_loss: 0.6853 - val_accuracy: 0.5630\n","Epoch 16/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5191 - val_loss: 0.6947 - val_accuracy: 0.4370\n","Epoch 17/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6954 - accuracy: 0.4942 - val_loss: 0.6909 - val_accuracy: 0.5630\n","Epoch 18/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.5015 - val_loss: 0.6867 - val_accuracy: 0.5630\n","Epoch 19/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6906 - accuracy: 0.5402 - val_loss: 0.6914 - val_accuracy: 0.5630\n","Epoch 20/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5264 - val_loss: 0.6992 - val_accuracy: 0.4370\n","Epoch 21/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.5168 - val_loss: 0.6862 - val_accuracy: 0.5630\n","Epoch 22/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6925 - accuracy: 0.5273 - val_loss: 0.6958 - val_accuracy: 0.4370\n","Epoch 23/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6943 - accuracy: 0.4961 - val_loss: 0.6861 - val_accuracy: 0.5630\n","Epoch 24/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5302 - val_loss: 0.6852 - val_accuracy: 0.5630\n","Epoch 25/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6922 - accuracy: 0.5207 - val_loss: 0.6854 - val_accuracy: 0.5630\n","Epoch 26/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6943 - accuracy: 0.5113 - val_loss: 0.6905 - val_accuracy: 0.5630\n","Epoch 27/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6916 - accuracy: 0.5334 - val_loss: 0.6930 - val_accuracy: 0.5630\n","Epoch 28/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6923 - accuracy: 0.5280 - val_loss: 0.6898 - val_accuracy: 0.5630\n","Epoch 29/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6920 - accuracy: 0.5340 - val_loss: 0.6890 - val_accuracy: 0.5630\n","Epoch 30/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6930 - accuracy: 0.5168 - val_loss: 0.6852 - val_accuracy: 0.5630\n","Epoch 31/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6920 - accuracy: 0.5275 - val_loss: 0.6988 - val_accuracy: 0.4370\n","Epoch 32/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6940 - accuracy: 0.5112 - val_loss: 0.6859 - val_accuracy: 0.5630\n","Epoch 33/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6913 - accuracy: 0.5315 - val_loss: 0.6874 - val_accuracy: 0.5630\n","Epoch 34/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6923 - accuracy: 0.5290 - val_loss: 0.6887 - val_accuracy: 0.5630\n","Epoch 35/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5270 - val_loss: 0.6937 - val_accuracy: 0.4370\n","Epoch 36/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6956 - accuracy: 0.4878 - val_loss: 0.6854 - val_accuracy: 0.5630\n","Epoch 37/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6921 - accuracy: 0.5158 - val_loss: 0.6991 - val_accuracy: 0.4370\n","Epoch 38/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6952 - accuracy: 0.4849 - val_loss: 0.6868 - val_accuracy: 0.5630\n","Epoch 39/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5259 - val_loss: 0.6909 - val_accuracy: 0.5630\n","Epoch 40/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6914 - accuracy: 0.5342 - val_loss: 0.6953 - val_accuracy: 0.4370\n","Epoch 41/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6945 - accuracy: 0.4950 - val_loss: 0.6883 - val_accuracy: 0.5630\n","Epoch 42/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6942 - accuracy: 0.5059 - val_loss: 0.6876 - val_accuracy: 0.5630\n","Epoch 43/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6920 - accuracy: 0.5281 - val_loss: 0.6884 - val_accuracy: 0.5630\n","Epoch 44/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5165 - val_loss: 0.6853 - val_accuracy: 0.5630\n","Epoch 45/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6930 - accuracy: 0.5300 - val_loss: 0.6926 - val_accuracy: 0.5630\n","Epoch 46/100\n","82/82 [==============================] - 0s 4ms/step - loss: 0.6925 - accuracy: 0.5300 - val_loss: 0.6855 - val_accuracy: 0.5630\n","Epoch 47/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6925 - accuracy: 0.5255 - val_loss: 0.6925 - val_accuracy: 0.5630\n","Epoch 48/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6917 - accuracy: 0.5378 - val_loss: 0.6863 - val_accuracy: 0.5630\n","Epoch 49/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.5157 - val_loss: 0.6855 - val_accuracy: 0.5630\n","Epoch 50/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.5239 - val_loss: 0.6919 - val_accuracy: 0.5630\n","Epoch 51/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.5024 - val_loss: 0.6858 - val_accuracy: 0.5630\n","Epoch 52/100\n","82/82 [==============================] - 0s 4ms/step - loss: 0.6947 - accuracy: 0.5038 - val_loss: 0.6919 - val_accuracy: 0.5630\n","Epoch 53/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6918 - accuracy: 0.5344 - val_loss: 0.6891 - val_accuracy: 0.5630\n","Epoch 54/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6952 - accuracy: 0.5057 - val_loss: 0.6943 - val_accuracy: 0.4370\n","Epoch 55/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6921 - accuracy: 0.5219 - val_loss: 0.7087 - val_accuracy: 0.4370\n","Epoch 56/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5258 - val_loss: 0.6884 - val_accuracy: 0.5630\n","Epoch 57/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.5212 - val_loss: 0.6966 - val_accuracy: 0.4370\n","Epoch 58/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.5118 - val_loss: 0.6867 - val_accuracy: 0.5630\n","Epoch 59/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6945 - accuracy: 0.5144 - val_loss: 0.6852 - val_accuracy: 0.5630\n","Epoch 60/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6955 - accuracy: 0.5148 - val_loss: 0.6894 - val_accuracy: 0.5630\n","Epoch 61/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.5112 - val_loss: 0.6937 - val_accuracy: 0.4370\n","Epoch 62/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6945 - accuracy: 0.5062 - val_loss: 0.6895 - val_accuracy: 0.5630\n","Epoch 63/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6914 - accuracy: 0.5306 - val_loss: 0.6857 - val_accuracy: 0.5630\n","Epoch 64/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6946 - accuracy: 0.5188 - val_loss: 0.6916 - val_accuracy: 0.5630\n","Epoch 65/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5177 - val_loss: 0.6857 - val_accuracy: 0.5630\n","Epoch 66/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5255 - val_loss: 0.6879 - val_accuracy: 0.5630\n","Epoch 67/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.5147 - val_loss: 0.6854 - val_accuracy: 0.5630\n","Epoch 68/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6919 - accuracy: 0.5272 - val_loss: 0.6853 - val_accuracy: 0.5630\n","Epoch 69/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6940 - accuracy: 0.5184 - val_loss: 0.6876 - val_accuracy: 0.5630\n","Epoch 70/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6930 - accuracy: 0.5227 - val_loss: 0.6866 - val_accuracy: 0.5630\n","Epoch 71/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5073 - val_loss: 0.6922 - val_accuracy: 0.5630\n","Epoch 72/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5137 - val_loss: 0.6856 - val_accuracy: 0.5630\n","Epoch 73/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6897 - accuracy: 0.5437 - val_loss: 0.6852 - val_accuracy: 0.5630\n","Epoch 74/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.5169 - val_loss: 0.6854 - val_accuracy: 0.5630\n","Epoch 75/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6923 - accuracy: 0.5316 - val_loss: 0.6897 - val_accuracy: 0.5630\n","Epoch 76/100\n","82/82 [==============================] - 0s 4ms/step - loss: 0.6918 - accuracy: 0.5362 - val_loss: 0.6911 - val_accuracy: 0.5630\n","Epoch 77/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6928 - accuracy: 0.5207 - val_loss: 0.6876 - val_accuracy: 0.5630\n","Epoch 78/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6925 - accuracy: 0.5230 - val_loss: 0.6853 - val_accuracy: 0.5630\n","Epoch 79/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6925 - accuracy: 0.5272 - val_loss: 0.6892 - val_accuracy: 0.5630\n","Epoch 80/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.5066 - val_loss: 0.6888 - val_accuracy: 0.5630\n","Epoch 81/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5251 - val_loss: 0.6853 - val_accuracy: 0.5630\n","Epoch 82/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5200 - val_loss: 0.6868 - val_accuracy: 0.5630\n","Epoch 83/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5217 - val_loss: 0.6858 - val_accuracy: 0.5630\n","Epoch 84/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.5145 - val_loss: 0.6860 - val_accuracy: 0.5630\n","Epoch 85/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6930 - accuracy: 0.5088 - val_loss: 0.6872 - val_accuracy: 0.5630\n","Epoch 86/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.5105 - val_loss: 0.6852 - val_accuracy: 0.5630\n","Epoch 87/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5124 - val_loss: 0.6927 - val_accuracy: 0.5630\n","Epoch 88/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5189 - val_loss: 0.6955 - val_accuracy: 0.4370\n","Epoch 89/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.4986 - val_loss: 0.6866 - val_accuracy: 0.5630\n","Epoch 90/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.5147 - val_loss: 0.6852 - val_accuracy: 0.5630\n","Epoch 91/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6944 - accuracy: 0.5139 - val_loss: 0.6945 - val_accuracy: 0.4370\n","Epoch 92/100\n","82/82 [==============================] - 0s 4ms/step - loss: 0.6940 - accuracy: 0.4984 - val_loss: 0.6911 - val_accuracy: 0.5630\n","Epoch 93/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6979 - accuracy: 0.4885 - val_loss: 0.6898 - val_accuracy: 0.5630\n","Epoch 94/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5060 - val_loss: 0.6854 - val_accuracy: 0.5630\n","Epoch 95/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6961 - accuracy: 0.5039 - val_loss: 0.6902 - val_accuracy: 0.5630\n","Epoch 96/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.5078 - val_loss: 0.6874 - val_accuracy: 0.5630\n","Epoch 97/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6919 - accuracy: 0.5331 - val_loss: 0.6950 - val_accuracy: 0.4370\n","Epoch 98/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6928 - accuracy: 0.5090 - val_loss: 0.6876 - val_accuracy: 0.5630\n","Epoch 99/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5170 - val_loss: 0.6857 - val_accuracy: 0.5630\n","Epoch 100/100\n","82/82 [==============================] - 0s 4ms/step - loss: 0.6949 - accuracy: 0.5083 - val_loss: 0.6852 - val_accuracy: 0.5630\n","CPU times: user 31.9 s, sys: 2.02 s, total: 34 s\n","Wall time: 27.9 s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9_skIQ-m83Zk","executionInfo":{"status":"ok","timestamp":1618195282743,"user_tz":240,"elapsed":750,"user":{"displayName":"Jingkai Xu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg2sWxfWEtas0OHVeRAKACfv2J-WqEkZOHE68L3EA=s64","userId":"14485307633456209780"}},"outputId":"91b16c25-7670-472c-cec9-59c43b87e57b"},"source":["_, accuracy = model.evaluate(X_test, y_test)\n","print('Accuracy: %.2f' % (accuracy*100))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["46/46 [==============================] - 0s 1ms/step - loss: 0.6908 - accuracy: 0.5394\n","Accuracy: 53.94\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"elf5Wl5Hb9c0"},"source":["# Adadelta"]},{"cell_type":"markdown","metadata":{"id":"PfBTzpvk8Lis"},"source":["## batch 32"]},{"cell_type":"code","metadata":{"id":"oPWa4DMU6Ls6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618200457805,"user_tz":240,"elapsed":36228,"user":{"displayName":"Jingkai Xu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg2sWxfWEtas0OHVeRAKACfv2J-WqEkZOHE68L3EA=s64","userId":"14485307633456209780"}},"outputId":"7f622089-a906-4828-ff1c-15fb5f31e876"},"source":["%%time\n","tf.random.set_seed(424)\n","print(\"current days: \", num_days)\n","# define the keras model\n","model = Sequential()\n","model.add(Dense(60, input_dim=10*num_days, activation='relu'))\n","model.add(Dense(128, activation='relu'))\n","# model.add(Dense(128, activation='relu'))\n","# model.add(Dense(20, activation='relu'))\n","# model.add(Dense(1, activation='sigmoid'))\n","\n","model.add(Dense(128, activation='relu'))\n","model.add(Dense(20, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","# opt = keras.optimizers.Adam(learning_rate=0.1)\n","opt = keras.optimizers.Adadelta(\n","    learning_rate=0.1, rho=0.95, epsilon=1e-07, name=\"Adadelta\"\n","        )\n","model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n","\n","model.fit(X_train, y_train, epochs=100, validation_split=0.1)\n","# mlp__validation_split=0.3"],"execution_count":null,"outputs":[{"output_type":"stream","text":["current days:  3\n","Epoch 1/100\n","163/163 [==============================] - 1s 3ms/step - loss: 0.6937 - accuracy: 0.5014 - val_loss: 0.6875 - val_accuracy: 0.5751\n","Epoch 2/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6899 - accuracy: 0.5319 - val_loss: 0.6854 - val_accuracy: 0.5820\n","Epoch 3/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6870 - accuracy: 0.5507 - val_loss: 0.6842 - val_accuracy: 0.5786\n","Epoch 4/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6895 - accuracy: 0.5370 - val_loss: 0.6814 - val_accuracy: 0.5751\n","Epoch 5/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6850 - accuracy: 0.5541 - val_loss: 0.6814 - val_accuracy: 0.5803\n","Epoch 6/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6871 - accuracy: 0.5443 - val_loss: 0.6838 - val_accuracy: 0.5769\n","Epoch 7/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6856 - accuracy: 0.5592 - val_loss: 0.6811 - val_accuracy: 0.5820\n","Epoch 8/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6838 - accuracy: 0.5603 - val_loss: 0.6825 - val_accuracy: 0.5786\n","Epoch 9/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6850 - accuracy: 0.5591 - val_loss: 0.6825 - val_accuracy: 0.5613\n","Epoch 10/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6834 - accuracy: 0.5553 - val_loss: 0.6813 - val_accuracy: 0.5820\n","Epoch 11/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6825 - accuracy: 0.5605 - val_loss: 0.6811 - val_accuracy: 0.5820\n","Epoch 12/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6833 - accuracy: 0.5566 - val_loss: 0.6796 - val_accuracy: 0.5872\n","Epoch 13/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6846 - accuracy: 0.5505 - val_loss: 0.6804 - val_accuracy: 0.5786\n","Epoch 14/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6856 - accuracy: 0.5531 - val_loss: 0.6837 - val_accuracy: 0.5648\n","Epoch 15/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6845 - accuracy: 0.5539 - val_loss: 0.6811 - val_accuracy: 0.5648\n","Epoch 16/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6811 - accuracy: 0.5682 - val_loss: 0.6821 - val_accuracy: 0.5596\n","Epoch 17/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6813 - accuracy: 0.5622 - val_loss: 0.6843 - val_accuracy: 0.5630\n","Epoch 18/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6825 - accuracy: 0.5589 - val_loss: 0.6807 - val_accuracy: 0.5630\n","Epoch 19/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6782 - accuracy: 0.5791 - val_loss: 0.6834 - val_accuracy: 0.5458\n","Epoch 20/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6801 - accuracy: 0.5731 - val_loss: 0.6842 - val_accuracy: 0.5544\n","Epoch 21/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6775 - accuracy: 0.5781 - val_loss: 0.6818 - val_accuracy: 0.5579\n","Epoch 22/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6772 - accuracy: 0.5760 - val_loss: 0.6834 - val_accuracy: 0.5561\n","Epoch 23/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6788 - accuracy: 0.5750 - val_loss: 0.6803 - val_accuracy: 0.5717\n","Epoch 24/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6769 - accuracy: 0.5731 - val_loss: 0.6820 - val_accuracy: 0.5509\n","Epoch 25/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6795 - accuracy: 0.5706 - val_loss: 0.6815 - val_accuracy: 0.5561\n","Epoch 26/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6774 - accuracy: 0.5718 - val_loss: 0.6826 - val_accuracy: 0.5613\n","Epoch 27/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6777 - accuracy: 0.5685 - val_loss: 0.6825 - val_accuracy: 0.5475\n","Epoch 28/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6724 - accuracy: 0.5894 - val_loss: 0.6847 - val_accuracy: 0.5371\n","Epoch 29/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6768 - accuracy: 0.5772 - val_loss: 0.6835 - val_accuracy: 0.5458\n","Epoch 30/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6804 - accuracy: 0.5692 - val_loss: 0.6804 - val_accuracy: 0.5717\n","Epoch 31/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6760 - accuracy: 0.5806 - val_loss: 0.6900 - val_accuracy: 0.5216\n","Epoch 32/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6777 - accuracy: 0.5772 - val_loss: 0.6830 - val_accuracy: 0.5596\n","Epoch 33/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6773 - accuracy: 0.5818 - val_loss: 0.6821 - val_accuracy: 0.5458\n","Epoch 34/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6764 - accuracy: 0.5762 - val_loss: 0.6840 - val_accuracy: 0.5527\n","Epoch 35/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6734 - accuracy: 0.5857 - val_loss: 0.6822 - val_accuracy: 0.5492\n","Epoch 36/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6770 - accuracy: 0.5756 - val_loss: 0.6811 - val_accuracy: 0.5648\n","Epoch 37/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6765 - accuracy: 0.5773 - val_loss: 0.6861 - val_accuracy: 0.5354\n","Epoch 38/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6765 - accuracy: 0.5660 - val_loss: 0.6808 - val_accuracy: 0.5682\n","Epoch 39/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6748 - accuracy: 0.5804 - val_loss: 0.6820 - val_accuracy: 0.5544\n","Epoch 40/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6770 - accuracy: 0.5734 - val_loss: 0.6909 - val_accuracy: 0.5181\n","Epoch 41/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6724 - accuracy: 0.5829 - val_loss: 0.6822 - val_accuracy: 0.5648\n","Epoch 42/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6761 - accuracy: 0.5740 - val_loss: 0.6834 - val_accuracy: 0.5561\n","Epoch 43/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6758 - accuracy: 0.5763 - val_loss: 0.6836 - val_accuracy: 0.5527\n","Epoch 44/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6748 - accuracy: 0.5896 - val_loss: 0.6799 - val_accuracy: 0.5717\n","Epoch 45/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6754 - accuracy: 0.5779 - val_loss: 0.6853 - val_accuracy: 0.5199\n","Epoch 46/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6766 - accuracy: 0.5673 - val_loss: 0.6803 - val_accuracy: 0.5579\n","Epoch 47/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6693 - accuracy: 0.5881 - val_loss: 0.6853 - val_accuracy: 0.5233\n","Epoch 48/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6732 - accuracy: 0.5835 - val_loss: 0.6830 - val_accuracy: 0.5579\n","Epoch 49/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6748 - accuracy: 0.5762 - val_loss: 0.6801 - val_accuracy: 0.5769\n","Epoch 50/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6678 - accuracy: 0.6035 - val_loss: 0.6903 - val_accuracy: 0.5199\n","Epoch 51/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6682 - accuracy: 0.5878 - val_loss: 0.6804 - val_accuracy: 0.5786\n","Epoch 52/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6735 - accuracy: 0.5773 - val_loss: 0.6815 - val_accuracy: 0.5596\n","Epoch 53/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6706 - accuracy: 0.5821 - val_loss: 0.6829 - val_accuracy: 0.5613\n","Epoch 54/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6709 - accuracy: 0.5818 - val_loss: 0.6832 - val_accuracy: 0.5492\n","Epoch 55/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6717 - accuracy: 0.5895 - val_loss: 0.6884 - val_accuracy: 0.5216\n","Epoch 56/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6736 - accuracy: 0.5793 - val_loss: 0.6825 - val_accuracy: 0.5527\n","Epoch 57/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6750 - accuracy: 0.5774 - val_loss: 0.6864 - val_accuracy: 0.5250\n","Epoch 58/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6726 - accuracy: 0.5853 - val_loss: 0.6810 - val_accuracy: 0.5682\n","Epoch 59/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6699 - accuracy: 0.5845 - val_loss: 0.6788 - val_accuracy: 0.5838\n","Epoch 60/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6712 - accuracy: 0.5756 - val_loss: 0.6827 - val_accuracy: 0.5665\n","Epoch 61/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6735 - accuracy: 0.5763 - val_loss: 0.6844 - val_accuracy: 0.5440\n","Epoch 62/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6707 - accuracy: 0.5806 - val_loss: 0.6825 - val_accuracy: 0.5613\n","Epoch 63/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6661 - accuracy: 0.5903 - val_loss: 0.6828 - val_accuracy: 0.5682\n","Epoch 64/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6725 - accuracy: 0.5778 - val_loss: 0.6799 - val_accuracy: 0.5630\n","Epoch 65/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6678 - accuracy: 0.5856 - val_loss: 0.6806 - val_accuracy: 0.5699\n","Epoch 66/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6689 - accuracy: 0.5880 - val_loss: 0.6838 - val_accuracy: 0.5527\n","Epoch 67/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6710 - accuracy: 0.5767 - val_loss: 0.6820 - val_accuracy: 0.5561\n","Epoch 68/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6702 - accuracy: 0.5867 - val_loss: 0.6792 - val_accuracy: 0.5751\n","Epoch 69/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6662 - accuracy: 0.5899 - val_loss: 0.6816 - val_accuracy: 0.5596\n","Epoch 70/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6695 - accuracy: 0.5869 - val_loss: 0.6822 - val_accuracy: 0.5527\n","Epoch 71/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6690 - accuracy: 0.5840 - val_loss: 0.6848 - val_accuracy: 0.5354\n","Epoch 72/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6714 - accuracy: 0.5868 - val_loss: 0.6784 - val_accuracy: 0.5665\n","Epoch 73/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6631 - accuracy: 0.5962 - val_loss: 0.6809 - val_accuracy: 0.5544\n","Epoch 74/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6684 - accuracy: 0.5854 - val_loss: 0.6827 - val_accuracy: 0.5509\n","Epoch 75/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6656 - accuracy: 0.5837 - val_loss: 0.6888 - val_accuracy: 0.5371\n","Epoch 76/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6619 - accuracy: 0.6017 - val_loss: 0.6838 - val_accuracy: 0.5579\n","Epoch 77/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6683 - accuracy: 0.5882 - val_loss: 0.6835 - val_accuracy: 0.5579\n","Epoch 78/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6661 - accuracy: 0.5858 - val_loss: 0.6809 - val_accuracy: 0.5699\n","Epoch 79/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6652 - accuracy: 0.5819 - val_loss: 0.6801 - val_accuracy: 0.5561\n","Epoch 80/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6668 - accuracy: 0.5898 - val_loss: 0.6817 - val_accuracy: 0.5561\n","Epoch 81/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6680 - accuracy: 0.5881 - val_loss: 0.6792 - val_accuracy: 0.5682\n","Epoch 82/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6691 - accuracy: 0.5834 - val_loss: 0.6784 - val_accuracy: 0.5889\n","Epoch 83/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6651 - accuracy: 0.5954 - val_loss: 0.6797 - val_accuracy: 0.5699\n","Epoch 84/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6648 - accuracy: 0.5973 - val_loss: 0.6863 - val_accuracy: 0.5423\n","Epoch 85/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6632 - accuracy: 0.5934 - val_loss: 0.6802 - val_accuracy: 0.5544\n","Epoch 86/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6659 - accuracy: 0.5943 - val_loss: 0.6781 - val_accuracy: 0.5786\n","Epoch 87/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6660 - accuracy: 0.5956 - val_loss: 0.6823 - val_accuracy: 0.5613\n","Epoch 88/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6608 - accuracy: 0.6025 - val_loss: 0.6842 - val_accuracy: 0.5475\n","Epoch 89/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6606 - accuracy: 0.6092 - val_loss: 0.6773 - val_accuracy: 0.5838\n","Epoch 90/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6612 - accuracy: 0.6041 - val_loss: 0.6777 - val_accuracy: 0.5717\n","Epoch 91/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6630 - accuracy: 0.5980 - val_loss: 0.6818 - val_accuracy: 0.5440\n","Epoch 92/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6644 - accuracy: 0.5889 - val_loss: 0.6937 - val_accuracy: 0.5199\n","Epoch 93/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6643 - accuracy: 0.5868 - val_loss: 0.6814 - val_accuracy: 0.5665\n","Epoch 94/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6577 - accuracy: 0.6073 - val_loss: 0.6777 - val_accuracy: 0.5751\n","Epoch 95/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6645 - accuracy: 0.5959 - val_loss: 0.6817 - val_accuracy: 0.5406\n","Epoch 96/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6655 - accuracy: 0.5950 - val_loss: 0.6773 - val_accuracy: 0.5803\n","Epoch 97/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6611 - accuracy: 0.5902 - val_loss: 0.6815 - val_accuracy: 0.5475\n","Epoch 98/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6622 - accuracy: 0.5987 - val_loss: 0.6833 - val_accuracy: 0.5630\n","Epoch 99/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6590 - accuracy: 0.6043 - val_loss: 0.6851 - val_accuracy: 0.5475\n","Epoch 100/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6614 - accuracy: 0.5984 - val_loss: 0.6771 - val_accuracy: 0.5699\n","CPU times: user 42.6 s, sys: 2.09 s, total: 44.7 s\n","Wall time: 35.7 s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"334XopPA-DGG","executionInfo":{"status":"ok","timestamp":1618195552448,"user_tz":240,"elapsed":583,"user":{"displayName":"Jingkai Xu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg2sWxfWEtas0OHVeRAKACfv2J-WqEkZOHE68L3EA=s64","userId":"14485307633456209780"}},"outputId":"200a7537-4a35-4023-d636-7b3820f950f3"},"source":["_, accuracy = model.evaluate(X_test, y_test)\n","print('Accuracy: %.2f' % (accuracy*100))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["46/46 [==============================] - 0s 1ms/step - loss: 0.6994 - accuracy: 0.5463\n","Accuracy: 54.63\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7n-Igfie9xuw"},"source":["## batch 64"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ETNLncam9uRv","executionInfo":{"status":"ok","timestamp":1618195477220,"user_tz":240,"elapsed":25421,"user":{"displayName":"Jingkai Xu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg2sWxfWEtas0OHVeRAKACfv2J-WqEkZOHE68L3EA=s64","userId":"14485307633456209780"}},"outputId":"998a71ca-7bde-41f9-cd68-dd65005f8737"},"source":["%%time\n","tf.random.set_seed(424)\n","print(\"current days: \", num_days)\n","# define the keras model\n","model = Sequential()\n","model.add(Dense(60, input_dim=10*num_days, activation='relu'))\n","model.add(Dense(128, activation='relu'))\n","# model.add(Dense(128, activation='relu'))\n","# model.add(Dense(20, activation='relu'))\n","# model.add(Dense(1, activation='sigmoid'))\n","\n","model.add(Dense(128, activation='relu'))\n","model.add(Dense(20, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","# opt = keras.optimizers.Adam(learning_rate=0.1)\n","opt = keras.optimizers.Adadelta(\n","    learning_rate=0.1, rho=0.95, epsilon=1e-07, name=\"Adadelta\"\n","        )\n","model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n","\n","model.fit(X_train, y_train, epochs=100,batch_size = 64, validation_split=0.1)\n","# mlp__validation_split=0.3"],"execution_count":null,"outputs":[{"output_type":"stream","text":["current days:  3\n","Epoch 1/100\n","82/82 [==============================] - 1s 5ms/step - loss: 0.6943 - accuracy: 0.4906 - val_loss: 0.6889 - val_accuracy: 0.5682\n","Epoch 2/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6908 - accuracy: 0.5298 - val_loss: 0.6859 - val_accuracy: 0.5699\n","Epoch 3/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6879 - accuracy: 0.5410 - val_loss: 0.6850 - val_accuracy: 0.5751\n","Epoch 4/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6903 - accuracy: 0.5269 - val_loss: 0.6829 - val_accuracy: 0.5734\n","Epoch 5/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6865 - accuracy: 0.5479 - val_loss: 0.6827 - val_accuracy: 0.5786\n","Epoch 6/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6879 - accuracy: 0.5399 - val_loss: 0.6846 - val_accuracy: 0.5820\n","Epoch 7/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6865 - accuracy: 0.5524 - val_loss: 0.6827 - val_accuracy: 0.5941\n","Epoch 8/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6854 - accuracy: 0.5608 - val_loss: 0.6828 - val_accuracy: 0.5872\n","Epoch 9/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6867 - accuracy: 0.5505 - val_loss: 0.6823 - val_accuracy: 0.5907\n","Epoch 10/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6852 - accuracy: 0.5544 - val_loss: 0.6815 - val_accuracy: 0.5907\n","Epoch 11/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6847 - accuracy: 0.5520 - val_loss: 0.6822 - val_accuracy: 0.5872\n","Epoch 12/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6853 - accuracy: 0.5635 - val_loss: 0.6804 - val_accuracy: 0.5820\n","Epoch 13/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6866 - accuracy: 0.5501 - val_loss: 0.6805 - val_accuracy: 0.5872\n","Epoch 14/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6869 - accuracy: 0.5531 - val_loss: 0.6822 - val_accuracy: 0.5751\n","Epoch 15/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6857 - accuracy: 0.5584 - val_loss: 0.6813 - val_accuracy: 0.5751\n","Epoch 16/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6831 - accuracy: 0.5643 - val_loss: 0.6808 - val_accuracy: 0.5803\n","Epoch 17/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6828 - accuracy: 0.5638 - val_loss: 0.6832 - val_accuracy: 0.5682\n","Epoch 18/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6840 - accuracy: 0.5632 - val_loss: 0.6804 - val_accuracy: 0.5751\n","Epoch 19/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6802 - accuracy: 0.5733 - val_loss: 0.6820 - val_accuracy: 0.5544\n","Epoch 20/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6818 - accuracy: 0.5668 - val_loss: 0.6835 - val_accuracy: 0.5596\n","Epoch 21/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6795 - accuracy: 0.5776 - val_loss: 0.6802 - val_accuracy: 0.5717\n","Epoch 22/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6792 - accuracy: 0.5683 - val_loss: 0.6815 - val_accuracy: 0.5613\n","Epoch 23/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6805 - accuracy: 0.5629 - val_loss: 0.6801 - val_accuracy: 0.5803\n","Epoch 24/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6790 - accuracy: 0.5702 - val_loss: 0.6809 - val_accuracy: 0.5613\n","Epoch 25/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6815 - accuracy: 0.5612 - val_loss: 0.6815 - val_accuracy: 0.5630\n","Epoch 26/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6792 - accuracy: 0.5635 - val_loss: 0.6813 - val_accuracy: 0.5630\n","Epoch 27/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6792 - accuracy: 0.5684 - val_loss: 0.6818 - val_accuracy: 0.5509\n","Epoch 28/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6750 - accuracy: 0.5846 - val_loss: 0.6830 - val_accuracy: 0.5458\n","Epoch 29/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6782 - accuracy: 0.5772 - val_loss: 0.6816 - val_accuracy: 0.5544\n","Epoch 30/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6812 - accuracy: 0.5609 - val_loss: 0.6794 - val_accuracy: 0.5872\n","Epoch 31/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6779 - accuracy: 0.5749 - val_loss: 0.6872 - val_accuracy: 0.5371\n","Epoch 32/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6793 - accuracy: 0.5748 - val_loss: 0.6807 - val_accuracy: 0.5648\n","Epoch 33/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6781 - accuracy: 0.5747 - val_loss: 0.6813 - val_accuracy: 0.5596\n","Epoch 34/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6786 - accuracy: 0.5728 - val_loss: 0.6827 - val_accuracy: 0.5423\n","Epoch 35/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6755 - accuracy: 0.5809 - val_loss: 0.6811 - val_accuracy: 0.5509\n","Epoch 36/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6785 - accuracy: 0.5695 - val_loss: 0.6803 - val_accuracy: 0.5699\n","Epoch 37/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6783 - accuracy: 0.5797 - val_loss: 0.6857 - val_accuracy: 0.5440\n","Epoch 38/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6789 - accuracy: 0.5647 - val_loss: 0.6802 - val_accuracy: 0.5613\n","Epoch 39/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6769 - accuracy: 0.5745 - val_loss: 0.6801 - val_accuracy: 0.5717\n","Epoch 40/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6781 - accuracy: 0.5730 - val_loss: 0.6889 - val_accuracy: 0.5164\n","Epoch 41/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6750 - accuracy: 0.5759 - val_loss: 0.6825 - val_accuracy: 0.5579\n","Epoch 42/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6775 - accuracy: 0.5719 - val_loss: 0.6815 - val_accuracy: 0.5596\n","Epoch 43/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6778 - accuracy: 0.5788 - val_loss: 0.6829 - val_accuracy: 0.5458\n","Epoch 44/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6768 - accuracy: 0.5836 - val_loss: 0.6795 - val_accuracy: 0.5786\n","Epoch 45/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6777 - accuracy: 0.5760 - val_loss: 0.6842 - val_accuracy: 0.5440\n","Epoch 46/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6789 - accuracy: 0.5678 - val_loss: 0.6802 - val_accuracy: 0.5717\n","Epoch 47/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6716 - accuracy: 0.5856 - val_loss: 0.6837 - val_accuracy: 0.5440\n","Epoch 48/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6758 - accuracy: 0.5737 - val_loss: 0.6815 - val_accuracy: 0.5579\n","Epoch 49/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6769 - accuracy: 0.5788 - val_loss: 0.6793 - val_accuracy: 0.5786\n","Epoch 50/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6718 - accuracy: 0.5986 - val_loss: 0.6882 - val_accuracy: 0.5164\n","Epoch 51/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6716 - accuracy: 0.5838 - val_loss: 0.6799 - val_accuracy: 0.5769\n","Epoch 52/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6761 - accuracy: 0.5746 - val_loss: 0.6803 - val_accuracy: 0.5665\n","Epoch 53/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6734 - accuracy: 0.5767 - val_loss: 0.6829 - val_accuracy: 0.5544\n","Epoch 54/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6737 - accuracy: 0.5746 - val_loss: 0.6817 - val_accuracy: 0.5561\n","Epoch 55/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6748 - accuracy: 0.5852 - val_loss: 0.6864 - val_accuracy: 0.5233\n","Epoch 56/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6773 - accuracy: 0.5763 - val_loss: 0.6825 - val_accuracy: 0.5509\n","Epoch 57/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6777 - accuracy: 0.5721 - val_loss: 0.6855 - val_accuracy: 0.5285\n","Epoch 58/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6761 - accuracy: 0.5693 - val_loss: 0.6801 - val_accuracy: 0.5699\n","Epoch 59/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6744 - accuracy: 0.5806 - val_loss: 0.6787 - val_accuracy: 0.5924\n","Epoch 60/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6740 - accuracy: 0.5781 - val_loss: 0.6815 - val_accuracy: 0.5613\n","Epoch 61/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6763 - accuracy: 0.5824 - val_loss: 0.6843 - val_accuracy: 0.5423\n","Epoch 62/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6750 - accuracy: 0.5782 - val_loss: 0.6831 - val_accuracy: 0.5717\n","Epoch 63/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6711 - accuracy: 0.5863 - val_loss: 0.6839 - val_accuracy: 0.5389\n","Epoch 64/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6759 - accuracy: 0.5707 - val_loss: 0.6803 - val_accuracy: 0.5648\n","Epoch 65/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6715 - accuracy: 0.5784 - val_loss: 0.6818 - val_accuracy: 0.5579\n","Epoch 66/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6731 - accuracy: 0.5759 - val_loss: 0.6826 - val_accuracy: 0.5509\n","Epoch 67/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6748 - accuracy: 0.5715 - val_loss: 0.6810 - val_accuracy: 0.5630\n","Epoch 68/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6744 - accuracy: 0.5804 - val_loss: 0.6800 - val_accuracy: 0.5699\n","Epoch 69/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6700 - accuracy: 0.5853 - val_loss: 0.6803 - val_accuracy: 0.5682\n","Epoch 70/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6736 - accuracy: 0.5768 - val_loss: 0.6831 - val_accuracy: 0.5665\n","Epoch 71/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6731 - accuracy: 0.5763 - val_loss: 0.6847 - val_accuracy: 0.5216\n","Epoch 72/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6750 - accuracy: 0.5797 - val_loss: 0.6787 - val_accuracy: 0.5855\n","Epoch 73/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6695 - accuracy: 0.5933 - val_loss: 0.6815 - val_accuracy: 0.5475\n","Epoch 74/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6742 - accuracy: 0.5759 - val_loss: 0.6805 - val_accuracy: 0.5648\n","Epoch 75/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6703 - accuracy: 0.5849 - val_loss: 0.6860 - val_accuracy: 0.5233\n","Epoch 76/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6675 - accuracy: 0.5934 - val_loss: 0.6834 - val_accuracy: 0.5509\n","Epoch 77/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6735 - accuracy: 0.5842 - val_loss: 0.6840 - val_accuracy: 0.5458\n","Epoch 78/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6708 - accuracy: 0.5752 - val_loss: 0.6804 - val_accuracy: 0.5665\n","Epoch 79/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6706 - accuracy: 0.5837 - val_loss: 0.6827 - val_accuracy: 0.5440\n","Epoch 80/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6725 - accuracy: 0.5750 - val_loss: 0.6809 - val_accuracy: 0.5492\n","Epoch 81/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6745 - accuracy: 0.5791 - val_loss: 0.6801 - val_accuracy: 0.5665\n","Epoch 82/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6741 - accuracy: 0.5766 - val_loss: 0.6793 - val_accuracy: 0.5717\n","Epoch 83/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6715 - accuracy: 0.5813 - val_loss: 0.6796 - val_accuracy: 0.5665\n","Epoch 84/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6712 - accuracy: 0.5862 - val_loss: 0.6836 - val_accuracy: 0.5613\n","Epoch 85/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6699 - accuracy: 0.5782 - val_loss: 0.6817 - val_accuracy: 0.5596\n","Epoch 86/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6723 - accuracy: 0.5744 - val_loss: 0.6787 - val_accuracy: 0.5924\n","Epoch 87/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6728 - accuracy: 0.5846 - val_loss: 0.6837 - val_accuracy: 0.5596\n","Epoch 88/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6684 - accuracy: 0.5784 - val_loss: 0.6859 - val_accuracy: 0.5337\n","Epoch 89/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6682 - accuracy: 0.5928 - val_loss: 0.6788 - val_accuracy: 0.5820\n","Epoch 90/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6687 - accuracy: 0.5868 - val_loss: 0.6800 - val_accuracy: 0.5648\n","Epoch 91/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6700 - accuracy: 0.5814 - val_loss: 0.6836 - val_accuracy: 0.5544\n","Epoch 92/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6712 - accuracy: 0.5799 - val_loss: 0.6891 - val_accuracy: 0.5250\n","Epoch 93/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6708 - accuracy: 0.5804 - val_loss: 0.6819 - val_accuracy: 0.5596\n","Epoch 94/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6660 - accuracy: 0.5894 - val_loss: 0.6795 - val_accuracy: 0.5717\n","Epoch 95/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6717 - accuracy: 0.5831 - val_loss: 0.6826 - val_accuracy: 0.5561\n","Epoch 96/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6731 - accuracy: 0.5787 - val_loss: 0.6798 - val_accuracy: 0.5665\n","Epoch 97/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6689 - accuracy: 0.5858 - val_loss: 0.6823 - val_accuracy: 0.5561\n","Epoch 98/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6693 - accuracy: 0.5902 - val_loss: 0.6818 - val_accuracy: 0.5596\n","Epoch 99/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6671 - accuracy: 0.5896 - val_loss: 0.6845 - val_accuracy: 0.5509\n","Epoch 100/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6694 - accuracy: 0.5866 - val_loss: 0.6786 - val_accuracy: 0.5769\n","CPU times: user 27.9 s, sys: 1.38 s, total: 29.3 s\n","Wall time: 24.6 s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uqx3072L9zZS","executionInfo":{"status":"ok","timestamp":1618195477945,"user_tz":240,"elapsed":723,"user":{"displayName":"Jingkai Xu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg2sWxfWEtas0OHVeRAKACfv2J-WqEkZOHE68L3EA=s64","userId":"14485307633456209780"}},"outputId":"35e0f69a-7bef-4758-9f46-69946ad58468"},"source":["_, accuracy = model.evaluate(X_test, y_test)\n","print('Accuracy: %.2f' % (accuracy*100))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["46/46 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.5470\n","Accuracy: 54.70\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"uCBYmu4bdCS7"},"source":["# SGD"]},{"cell_type":"markdown","metadata":{"id":"PFOzUzAn8ODU"},"source":["## batch 32"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o3qVh5pldDaT","executionInfo":{"status":"ok","timestamp":1618263289730,"user_tz":240,"elapsed":37603,"user":{"displayName":"Jingkai Xu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg2sWxfWEtas0OHVeRAKACfv2J-WqEkZOHE68L3EA=s64","userId":"14485307633456209780"}},"outputId":"f7082dbe-b440-4fe9-d2b5-a79c9e14b9f0"},"source":["%%time\n","tf.random.set_seed(424)\n","print(\"current days: \", num_days)\n","# define the keras model\n","model = Sequential()\n","model.add(Dense(60, input_dim=10*num_days, activation='relu'))\n","model.add(Dense(128, activation='relu'))\n","# model.add(Dense(128, activation='relu'))\n","# model.add(Dense(20, activation='relu'))\n","# model.add(Dense(1, activation='sigmoid'))\n","\n","model.add(Dense(128, activation='relu'))\n","model.add(Dense(20, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","# opt = keras.optimizers.Adam(learning_rate=0.1)\n","opt = keras.optimizers.SGD(learning_rate=0.1, nesterov=False, name=\"SGD\")\n","model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n","model.fit(X_train, y_train, epochs=100,validation_split=0.1)\n","# mlp__validation_split=0.3"],"execution_count":null,"outputs":[{"output_type":"stream","text":["current days:  3\n","Epoch 1/100\n","163/163 [==============================] - 1s 3ms/step - loss: 0.6938 - accuracy: 0.5039 - val_loss: 0.6868 - val_accuracy: 0.5803\n","Epoch 2/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6887 - accuracy: 0.5426 - val_loss: 0.6865 - val_accuracy: 0.5751\n","Epoch 3/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6862 - accuracy: 0.5576 - val_loss: 0.6813 - val_accuracy: 0.5803\n","Epoch 4/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6891 - accuracy: 0.5427 - val_loss: 0.6790 - val_accuracy: 0.5941\n","Epoch 5/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6824 - accuracy: 0.5517 - val_loss: 0.6786 - val_accuracy: 0.5993\n","Epoch 6/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6861 - accuracy: 0.5528 - val_loss: 0.6843 - val_accuracy: 0.5630\n","Epoch 7/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6846 - accuracy: 0.5615 - val_loss: 0.6784 - val_accuracy: 0.5769\n","Epoch 8/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6824 - accuracy: 0.5664 - val_loss: 0.6824 - val_accuracy: 0.5440\n","Epoch 9/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6838 - accuracy: 0.5555 - val_loss: 0.6860 - val_accuracy: 0.5423\n","Epoch 10/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6831 - accuracy: 0.5649 - val_loss: 0.6806 - val_accuracy: 0.5544\n","Epoch 11/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6816 - accuracy: 0.5608 - val_loss: 0.6884 - val_accuracy: 0.5320\n","Epoch 12/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6816 - accuracy: 0.5579 - val_loss: 0.6782 - val_accuracy: 0.5872\n","Epoch 13/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6841 - accuracy: 0.5475 - val_loss: 0.6790 - val_accuracy: 0.5803\n","Epoch 14/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6864 - accuracy: 0.5516 - val_loss: 0.6864 - val_accuracy: 0.5509\n","Epoch 15/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6852 - accuracy: 0.5491 - val_loss: 0.6811 - val_accuracy: 0.5699\n","Epoch 16/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6806 - accuracy: 0.5715 - val_loss: 0.6813 - val_accuracy: 0.5596\n","Epoch 17/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6810 - accuracy: 0.5611 - val_loss: 0.6897 - val_accuracy: 0.5147\n","Epoch 18/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6834 - accuracy: 0.5551 - val_loss: 0.6791 - val_accuracy: 0.5786\n","Epoch 19/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6791 - accuracy: 0.5696 - val_loss: 0.6840 - val_accuracy: 0.5389\n","Epoch 20/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6787 - accuracy: 0.5730 - val_loss: 0.6844 - val_accuracy: 0.5423\n","Epoch 21/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6774 - accuracy: 0.5717 - val_loss: 0.6835 - val_accuracy: 0.5389\n","Epoch 22/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6783 - accuracy: 0.5674 - val_loss: 0.6810 - val_accuracy: 0.5406\n","Epoch 23/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6787 - accuracy: 0.5647 - val_loss: 0.6789 - val_accuracy: 0.5769\n","Epoch 24/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6741 - accuracy: 0.5837 - val_loss: 0.6787 - val_accuracy: 0.5803\n","Epoch 25/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6778 - accuracy: 0.5739 - val_loss: 0.6825 - val_accuracy: 0.5354\n","Epoch 26/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6771 - accuracy: 0.5764 - val_loss: 0.6804 - val_accuracy: 0.5648\n","Epoch 27/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6760 - accuracy: 0.5728 - val_loss: 0.6776 - val_accuracy: 0.5751\n","Epoch 28/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6706 - accuracy: 0.5829 - val_loss: 0.6850 - val_accuracy: 0.5371\n","Epoch 29/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6773 - accuracy: 0.5866 - val_loss: 0.6794 - val_accuracy: 0.5648\n","Epoch 30/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6791 - accuracy: 0.5706 - val_loss: 0.6786 - val_accuracy: 0.5838\n","Epoch 31/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6754 - accuracy: 0.5755 - val_loss: 0.6964 - val_accuracy: 0.4974\n","Epoch 32/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6780 - accuracy: 0.5752 - val_loss: 0.6845 - val_accuracy: 0.5630\n","Epoch 33/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6759 - accuracy: 0.5802 - val_loss: 0.6784 - val_accuracy: 0.5734\n","Epoch 34/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6728 - accuracy: 0.5803 - val_loss: 0.6757 - val_accuracy: 0.5734\n","Epoch 35/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6708 - accuracy: 0.5872 - val_loss: 0.6772 - val_accuracy: 0.5561\n","Epoch 36/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6753 - accuracy: 0.5828 - val_loss: 0.6737 - val_accuracy: 0.5717\n","Epoch 37/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6729 - accuracy: 0.5881 - val_loss: 0.6822 - val_accuracy: 0.5302\n","Epoch 38/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6724 - accuracy: 0.5731 - val_loss: 0.6762 - val_accuracy: 0.5699\n","Epoch 39/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6726 - accuracy: 0.5858 - val_loss: 0.6740 - val_accuracy: 0.5665\n","Epoch 40/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6755 - accuracy: 0.5749 - val_loss: 0.6947 - val_accuracy: 0.5112\n","Epoch 41/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6693 - accuracy: 0.5855 - val_loss: 0.6765 - val_accuracy: 0.5544\n","Epoch 42/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6723 - accuracy: 0.5879 - val_loss: 0.6757 - val_accuracy: 0.5717\n","Epoch 43/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6728 - accuracy: 0.5848 - val_loss: 0.6786 - val_accuracy: 0.5648\n","Epoch 44/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6699 - accuracy: 0.5945 - val_loss: 0.6721 - val_accuracy: 0.5820\n","Epoch 45/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6724 - accuracy: 0.5834 - val_loss: 0.6776 - val_accuracy: 0.5769\n","Epoch 46/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6742 - accuracy: 0.5775 - val_loss: 0.6725 - val_accuracy: 0.5872\n","Epoch 47/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6659 - accuracy: 0.5983 - val_loss: 0.6730 - val_accuracy: 0.5838\n","Epoch 48/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6682 - accuracy: 0.5812 - val_loss: 0.6729 - val_accuracy: 0.5941\n","Epoch 49/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6719 - accuracy: 0.5798 - val_loss: 0.6705 - val_accuracy: 0.5630\n","Epoch 50/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6600 - accuracy: 0.6026 - val_loss: 0.6895 - val_accuracy: 0.5233\n","Epoch 51/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6627 - accuracy: 0.6002 - val_loss: 0.6750 - val_accuracy: 0.5889\n","Epoch 52/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6704 - accuracy: 0.5891 - val_loss: 0.6730 - val_accuracy: 0.5976\n","Epoch 53/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6670 - accuracy: 0.5911 - val_loss: 0.6750 - val_accuracy: 0.6079\n","Epoch 54/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6661 - accuracy: 0.5934 - val_loss: 0.6745 - val_accuracy: 0.5889\n","Epoch 55/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6686 - accuracy: 0.5900 - val_loss: 0.6835 - val_accuracy: 0.5561\n","Epoch 56/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6678 - accuracy: 0.5903 - val_loss: 0.6789 - val_accuracy: 0.5872\n","Epoch 57/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6704 - accuracy: 0.5841 - val_loss: 0.6857 - val_accuracy: 0.5354\n","Epoch 58/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6646 - accuracy: 0.5964 - val_loss: 0.6775 - val_accuracy: 0.6010\n","Epoch 59/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6639 - accuracy: 0.6039 - val_loss: 0.6686 - val_accuracy: 0.5976\n","Epoch 60/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6661 - accuracy: 0.5914 - val_loss: 0.6702 - val_accuracy: 0.5769\n","Epoch 61/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6686 - accuracy: 0.5855 - val_loss: 0.7026 - val_accuracy: 0.5164\n","Epoch 62/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6665 - accuracy: 0.5920 - val_loss: 0.6869 - val_accuracy: 0.5561\n","Epoch 63/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6599 - accuracy: 0.6040 - val_loss: 0.6754 - val_accuracy: 0.5630\n","Epoch 64/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6626 - accuracy: 0.6013 - val_loss: 0.6730 - val_accuracy: 0.5924\n","Epoch 65/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6631 - accuracy: 0.5936 - val_loss: 0.6751 - val_accuracy: 0.5769\n","Epoch 66/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6574 - accuracy: 0.6034 - val_loss: 0.6750 - val_accuracy: 0.5717\n","Epoch 67/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6614 - accuracy: 0.6023 - val_loss: 0.6742 - val_accuracy: 0.5803\n","Epoch 68/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6591 - accuracy: 0.6142 - val_loss: 0.6792 - val_accuracy: 0.5509\n","Epoch 69/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6573 - accuracy: 0.6053 - val_loss: 0.6722 - val_accuracy: 0.6079\n","Epoch 70/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6586 - accuracy: 0.6041 - val_loss: 0.6781 - val_accuracy: 0.5907\n","Epoch 71/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6593 - accuracy: 0.6044 - val_loss: 0.6795 - val_accuracy: 0.5544\n","Epoch 72/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6606 - accuracy: 0.5985 - val_loss: 0.6754 - val_accuracy: 0.5959\n","Epoch 73/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6516 - accuracy: 0.6193 - val_loss: 0.6815 - val_accuracy: 0.5423\n","Epoch 74/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6548 - accuracy: 0.6091 - val_loss: 0.6730 - val_accuracy: 0.5665\n","Epoch 75/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6538 - accuracy: 0.6135 - val_loss: 0.6853 - val_accuracy: 0.5475\n","Epoch 76/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6493 - accuracy: 0.6201 - val_loss: 0.6782 - val_accuracy: 0.5924\n","Epoch 77/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6550 - accuracy: 0.6135 - val_loss: 0.6845 - val_accuracy: 0.5596\n","Epoch 78/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6578 - accuracy: 0.6059 - val_loss: 0.6774 - val_accuracy: 0.5665\n","Epoch 79/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6529 - accuracy: 0.6149 - val_loss: 0.6828 - val_accuracy: 0.5924\n","Epoch 80/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6535 - accuracy: 0.6060 - val_loss: 0.6807 - val_accuracy: 0.5613\n","Epoch 81/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6509 - accuracy: 0.6096 - val_loss: 0.6794 - val_accuracy: 0.5682\n","Epoch 82/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6536 - accuracy: 0.6066 - val_loss: 0.6717 - val_accuracy: 0.5855\n","Epoch 83/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6526 - accuracy: 0.6236 - val_loss: 0.6727 - val_accuracy: 0.5803\n","Epoch 84/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6466 - accuracy: 0.6147 - val_loss: 0.7000 - val_accuracy: 0.5440\n","Epoch 85/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6458 - accuracy: 0.6184 - val_loss: 0.6744 - val_accuracy: 0.5941\n","Epoch 86/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6456 - accuracy: 0.6076 - val_loss: 0.6777 - val_accuracy: 0.6010\n","Epoch 87/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6492 - accuracy: 0.6116 - val_loss: 0.6863 - val_accuracy: 0.5855\n","Epoch 88/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6429 - accuracy: 0.6263 - val_loss: 0.6840 - val_accuracy: 0.5803\n","Epoch 89/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6368 - accuracy: 0.6341 - val_loss: 0.6758 - val_accuracy: 0.5682\n","Epoch 90/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6395 - accuracy: 0.6383 - val_loss: 0.6755 - val_accuracy: 0.5820\n","Epoch 91/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6392 - accuracy: 0.6379 - val_loss: 0.6752 - val_accuracy: 0.5803\n","Epoch 92/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6426 - accuracy: 0.6246 - val_loss: 0.7020 - val_accuracy: 0.5423\n","Epoch 93/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6437 - accuracy: 0.6174 - val_loss: 0.6843 - val_accuracy: 0.5492\n","Epoch 94/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6350 - accuracy: 0.6464 - val_loss: 0.6727 - val_accuracy: 0.5872\n","Epoch 95/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6463 - accuracy: 0.6158 - val_loss: 0.6852 - val_accuracy: 0.5527\n","Epoch 96/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6388 - accuracy: 0.6340 - val_loss: 0.6774 - val_accuracy: 0.5855\n","Epoch 97/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6354 - accuracy: 0.6239 - val_loss: 0.6873 - val_accuracy: 0.5665\n","Epoch 98/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6378 - accuracy: 0.6287 - val_loss: 0.6968 - val_accuracy: 0.5734\n","Epoch 99/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6314 - accuracy: 0.6423 - val_loss: 0.7094 - val_accuracy: 0.5406\n","Epoch 100/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6406 - accuracy: 0.6277 - val_loss: 0.6779 - val_accuracy: 0.5734\n","CPU times: user 42.3 s, sys: 2.9 s, total: 45.2 s\n","Wall time: 37.4 s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_K2D6nK9Ajoo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618263293662,"user_tz":240,"elapsed":520,"user":{"displayName":"Jingkai Xu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg2sWxfWEtas0OHVeRAKACfv2J-WqEkZOHE68L3EA=s64","userId":"14485307633456209780"}},"outputId":"34d9317e-a54c-41cc-85c6-bc9f8dd5d6b8"},"source":["_, accuracy = model.evaluate(X_test, y_test)\n","print('Accuracy: %.2f' % (accuracy*100))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["46/46 [==============================] - 0s 1ms/step - loss: 0.7296 - accuracy: 0.5242\n","Accuracy: 52.42\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WFzjuF5mzZJX","executionInfo":{"status":"ok","timestamp":1618259848665,"user_tz":240,"elapsed":274,"user":{"displayName":"Jingkai Xu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg2sWxfWEtas0OHVeRAKACfv2J-WqEkZOHE68L3EA=s64","userId":"14485307633456209780"}},"outputId":"9c36e623-3f90-46d4-cd47-cbf9706b5298"},"source":["_, accuracy = model.evaluate(X_test, y_test)\n","print('Accuracy: %.2f' % (accuracy*100))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["46/46 [==============================] - 0s 1ms/step - loss: 0.7322 - accuracy: 0.5394\n","Accuracy: 53.94\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_5MPft_-9YY3"},"source":["## batch 64"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DjcrPhsM1-ib","executionInfo":{"status":"ok","timestamp":1618195407116,"user_tz":240,"elapsed":24306,"user":{"displayName":"Jingkai Xu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg2sWxfWEtas0OHVeRAKACfv2J-WqEkZOHE68L3EA=s64","userId":"14485307633456209780"}},"outputId":"1f3e49fd-2ac0-42ca-e924-7a94b9574efd"},"source":["%%time\n","tf.random.set_seed(424)\n","print(\"current days: \", num_days)\n","# define the keras model\n","model = Sequential()\n","model.add(Dense(60, input_dim=10*num_days, activation='relu'))\n","model.add(Dense(128, activation='relu'))\n","# model.add(Dense(128, activation='relu'))\n","# model.add(Dense(20, activation='relu'))\n","# model.add(Dense(1, activation='sigmoid'))\n","\n","model.add(Dense(128, activation='relu'))\n","model.add(Dense(20, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","# opt = keras.optimizers.Adam(learning_rate=0.1)\n","opt = keras.optimizers.SGD(\n","    learning_rate=0.1, momentum=0.1, nesterov=False, name=\"SGD\"\n",")\n","model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n","model.fit(X_train, y_train, epochs=100, batch_size=64,validation_split=0.1)\n","\n","# mlp__validation_split=0.3"],"execution_count":null,"outputs":[{"output_type":"stream","text":["current days:  3\n","Epoch 1/100\n","82/82 [==============================] - 1s 5ms/step - loss: 0.6935 - accuracy: 0.4987 - val_loss: 0.6877 - val_accuracy: 0.5924\n","Epoch 2/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6892 - accuracy: 0.5396 - val_loss: 0.6857 - val_accuracy: 0.5820\n","Epoch 3/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6869 - accuracy: 0.5483 - val_loss: 0.6822 - val_accuracy: 0.5682\n","Epoch 4/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6901 - accuracy: 0.5321 - val_loss: 0.6805 - val_accuracy: 0.5855\n","Epoch 5/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6844 - accuracy: 0.5529 - val_loss: 0.6800 - val_accuracy: 0.5907\n","Epoch 6/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6871 - accuracy: 0.5496 - val_loss: 0.6862 - val_accuracy: 0.5717\n","Epoch 7/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6860 - accuracy: 0.5526 - val_loss: 0.6797 - val_accuracy: 0.5786\n","Epoch 8/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6837 - accuracy: 0.5562 - val_loss: 0.6827 - val_accuracy: 0.5648\n","Epoch 9/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6845 - accuracy: 0.5519 - val_loss: 0.6856 - val_accuracy: 0.5389\n","Epoch 10/100\n","82/82 [==============================] - 0s 2ms/step - loss: 0.6835 - accuracy: 0.5454 - val_loss: 0.6809 - val_accuracy: 0.5699\n","Epoch 11/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6828 - accuracy: 0.5609 - val_loss: 0.6907 - val_accuracy: 0.5302\n","Epoch 12/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6834 - accuracy: 0.5517 - val_loss: 0.6799 - val_accuracy: 0.5889\n","Epoch 13/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6858 - accuracy: 0.5466 - val_loss: 0.6782 - val_accuracy: 0.5838\n","Epoch 14/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6869 - accuracy: 0.5447 - val_loss: 0.6822 - val_accuracy: 0.5648\n","Epoch 15/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6850 - accuracy: 0.5493 - val_loss: 0.6841 - val_accuracy: 0.5596\n","Epoch 16/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6815 - accuracy: 0.5698 - val_loss: 0.6773 - val_accuracy: 0.5889\n","Epoch 17/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6816 - accuracy: 0.5731 - val_loss: 0.6946 - val_accuracy: 0.5026\n","Epoch 18/100\n","82/82 [==============================] - 0s 2ms/step - loss: 0.6842 - accuracy: 0.5527 - val_loss: 0.6794 - val_accuracy: 0.5665\n","Epoch 19/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6797 - accuracy: 0.5719 - val_loss: 0.6824 - val_accuracy: 0.5458\n","Epoch 20/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6800 - accuracy: 0.5673 - val_loss: 0.6903 - val_accuracy: 0.5164\n","Epoch 21/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6780 - accuracy: 0.5687 - val_loss: 0.6799 - val_accuracy: 0.5665\n","Epoch 22/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6777 - accuracy: 0.5676 - val_loss: 0.6801 - val_accuracy: 0.5648\n","Epoch 23/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6794 - accuracy: 0.5740 - val_loss: 0.6808 - val_accuracy: 0.5613\n","Epoch 24/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6765 - accuracy: 0.5789 - val_loss: 0.6808 - val_accuracy: 0.5648\n","Epoch 25/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6797 - accuracy: 0.5617 - val_loss: 0.6873 - val_accuracy: 0.5302\n","Epoch 26/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6790 - accuracy: 0.5673 - val_loss: 0.6801 - val_accuracy: 0.5803\n","Epoch 27/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6777 - accuracy: 0.5667 - val_loss: 0.6794 - val_accuracy: 0.5699\n","Epoch 28/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6731 - accuracy: 0.5761 - val_loss: 0.6844 - val_accuracy: 0.5337\n","Epoch 29/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6769 - accuracy: 0.5797 - val_loss: 0.6801 - val_accuracy: 0.5717\n","Epoch 30/100\n","82/82 [==============================] - 0s 2ms/step - loss: 0.6806 - accuracy: 0.5674 - val_loss: 0.6781 - val_accuracy: 0.5924\n","Epoch 31/100\n","82/82 [==============================] - 0s 2ms/step - loss: 0.6779 - accuracy: 0.5661 - val_loss: 0.6979 - val_accuracy: 0.4940\n","Epoch 32/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6787 - accuracy: 0.5827 - val_loss: 0.6871 - val_accuracy: 0.5199\n","Epoch 33/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6773 - accuracy: 0.5814 - val_loss: 0.6825 - val_accuracy: 0.5406\n","Epoch 34/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6761 - accuracy: 0.5728 - val_loss: 0.6772 - val_accuracy: 0.5717\n","Epoch 35/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6741 - accuracy: 0.5760 - val_loss: 0.6812 - val_accuracy: 0.5665\n","Epoch 36/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6767 - accuracy: 0.5717 - val_loss: 0.6796 - val_accuracy: 0.5734\n","Epoch 37/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6748 - accuracy: 0.5803 - val_loss: 0.6873 - val_accuracy: 0.5320\n","Epoch 38/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6760 - accuracy: 0.5715 - val_loss: 0.6773 - val_accuracy: 0.5889\n","Epoch 39/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6747 - accuracy: 0.5844 - val_loss: 0.6756 - val_accuracy: 0.5924\n","Epoch 40/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6770 - accuracy: 0.5698 - val_loss: 0.7059 - val_accuracy: 0.4853\n","Epoch 41/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6733 - accuracy: 0.5785 - val_loss: 0.6802 - val_accuracy: 0.5613\n","Epoch 42/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6755 - accuracy: 0.5764 - val_loss: 0.6782 - val_accuracy: 0.5855\n","Epoch 43/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6748 - accuracy: 0.5780 - val_loss: 0.6826 - val_accuracy: 0.5458\n","Epoch 44/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6727 - accuracy: 0.5882 - val_loss: 0.6767 - val_accuracy: 0.5803\n","Epoch 45/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6751 - accuracy: 0.5809 - val_loss: 0.6817 - val_accuracy: 0.5682\n","Epoch 46/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6769 - accuracy: 0.5636 - val_loss: 0.6752 - val_accuracy: 0.5889\n","Epoch 47/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6687 - accuracy: 0.5888 - val_loss: 0.6761 - val_accuracy: 0.5941\n","Epoch 48/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6707 - accuracy: 0.5811 - val_loss: 0.6750 - val_accuracy: 0.6045\n","Epoch 49/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6751 - accuracy: 0.5683 - val_loss: 0.6735 - val_accuracy: 0.6097\n","Epoch 50/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6657 - accuracy: 0.5997 - val_loss: 0.7039 - val_accuracy: 0.4922\n","Epoch 51/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6666 - accuracy: 0.5961 - val_loss: 0.6752 - val_accuracy: 0.6045\n","Epoch 52/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6737 - accuracy: 0.5779 - val_loss: 0.6754 - val_accuracy: 0.5924\n","Epoch 53/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6698 - accuracy: 0.5883 - val_loss: 0.6759 - val_accuracy: 0.5959\n","Epoch 54/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6697 - accuracy: 0.5852 - val_loss: 0.6750 - val_accuracy: 0.6062\n","Epoch 55/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6738 - accuracy: 0.5823 - val_loss: 0.6854 - val_accuracy: 0.5371\n","Epoch 56/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6704 - accuracy: 0.5858 - val_loss: 0.6810 - val_accuracy: 0.5544\n","Epoch 57/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6737 - accuracy: 0.5749 - val_loss: 0.6997 - val_accuracy: 0.5043\n","Epoch 58/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6726 - accuracy: 0.5737 - val_loss: 0.6755 - val_accuracy: 0.6079\n","Epoch 59/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6705 - accuracy: 0.5953 - val_loss: 0.6715 - val_accuracy: 0.5924\n","Epoch 60/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6694 - accuracy: 0.5787 - val_loss: 0.6716 - val_accuracy: 0.5872\n","Epoch 61/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6720 - accuracy: 0.5881 - val_loss: 0.7269 - val_accuracy: 0.4853\n","Epoch 62/100\n","82/82 [==============================] - 0s 2ms/step - loss: 0.6709 - accuracy: 0.5917 - val_loss: 0.6947 - val_accuracy: 0.5285\n","Epoch 63/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6669 - accuracy: 0.5920 - val_loss: 0.6909 - val_accuracy: 0.5320\n","Epoch 64/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6694 - accuracy: 0.5885 - val_loss: 0.6720 - val_accuracy: 0.5907\n","Epoch 65/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6671 - accuracy: 0.5950 - val_loss: 0.6807 - val_accuracy: 0.5613\n","Epoch 66/100\n","82/82 [==============================] - 0s 2ms/step - loss: 0.6631 - accuracy: 0.5961 - val_loss: 0.6873 - val_accuracy: 0.5320\n","Epoch 67/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6683 - accuracy: 0.5929 - val_loss: 0.6744 - val_accuracy: 0.5872\n","Epoch 68/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6678 - accuracy: 0.5856 - val_loss: 0.6876 - val_accuracy: 0.5630\n","Epoch 69/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6629 - accuracy: 0.5977 - val_loss: 0.6699 - val_accuracy: 0.6062\n","Epoch 70/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6635 - accuracy: 0.5970 - val_loss: 0.6844 - val_accuracy: 0.5648\n","Epoch 71/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6671 - accuracy: 0.5840 - val_loss: 0.6799 - val_accuracy: 0.5458\n","Epoch 72/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6677 - accuracy: 0.5836 - val_loss: 0.6756 - val_accuracy: 0.5855\n","Epoch 73/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6601 - accuracy: 0.6045 - val_loss: 0.6844 - val_accuracy: 0.5389\n","Epoch 74/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6628 - accuracy: 0.5871 - val_loss: 0.6716 - val_accuracy: 0.6149\n","Epoch 75/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6613 - accuracy: 0.5897 - val_loss: 0.6790 - val_accuracy: 0.5717\n","Epoch 76/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6577 - accuracy: 0.5981 - val_loss: 0.6740 - val_accuracy: 0.6062\n","Epoch 77/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6612 - accuracy: 0.6027 - val_loss: 0.6868 - val_accuracy: 0.5682\n","Epoch 78/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6641 - accuracy: 0.5987 - val_loss: 0.6791 - val_accuracy: 0.5751\n","Epoch 79/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6596 - accuracy: 0.6003 - val_loss: 0.6760 - val_accuracy: 0.5786\n","Epoch 80/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6602 - accuracy: 0.6072 - val_loss: 0.6780 - val_accuracy: 0.5717\n","Epoch 81/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6613 - accuracy: 0.5999 - val_loss: 0.6761 - val_accuracy: 0.5976\n","Epoch 82/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6622 - accuracy: 0.6056 - val_loss: 0.6714 - val_accuracy: 0.5838\n","Epoch 83/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6594 - accuracy: 0.6040 - val_loss: 0.6725 - val_accuracy: 0.5838\n","Epoch 84/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6561 - accuracy: 0.6098 - val_loss: 0.6897 - val_accuracy: 0.5509\n","Epoch 85/100\n","82/82 [==============================] - 0s 6ms/step - loss: 0.6539 - accuracy: 0.6126 - val_loss: 0.6729 - val_accuracy: 0.5889\n","Epoch 86/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6573 - accuracy: 0.5992 - val_loss: 0.6761 - val_accuracy: 0.5907\n","Epoch 87/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6593 - accuracy: 0.6142 - val_loss: 0.6920 - val_accuracy: 0.5579\n","Epoch 88/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6520 - accuracy: 0.6081 - val_loss: 0.6900 - val_accuracy: 0.5561\n","Epoch 89/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6517 - accuracy: 0.6180 - val_loss: 0.6730 - val_accuracy: 0.6010\n","Epoch 90/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6519 - accuracy: 0.6189 - val_loss: 0.6895 - val_accuracy: 0.5509\n","Epoch 91/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6517 - accuracy: 0.6129 - val_loss: 0.6736 - val_accuracy: 0.5924\n","Epoch 92/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6545 - accuracy: 0.6134 - val_loss: 0.6972 - val_accuracy: 0.5320\n","Epoch 93/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6584 - accuracy: 0.6032 - val_loss: 0.7011 - val_accuracy: 0.5371\n","Epoch 94/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6468 - accuracy: 0.6293 - val_loss: 0.6750 - val_accuracy: 0.6028\n","Epoch 95/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6569 - accuracy: 0.5994 - val_loss: 0.6899 - val_accuracy: 0.5492\n","Epoch 96/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6573 - accuracy: 0.6014 - val_loss: 0.6771 - val_accuracy: 0.5769\n","Epoch 97/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6515 - accuracy: 0.6161 - val_loss: 0.6819 - val_accuracy: 0.5682\n","Epoch 98/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6515 - accuracy: 0.6101 - val_loss: 0.6886 - val_accuracy: 0.5803\n","Epoch 99/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6505 - accuracy: 0.6159 - val_loss: 0.7195 - val_accuracy: 0.5233\n","Epoch 100/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6509 - accuracy: 0.6190 - val_loss: 0.6784 - val_accuracy: 0.5734\n","CPU times: user 26.8 s, sys: 1.32 s, total: 28.1 s\n","Wall time: 23.7 s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_nxR46tz6_DC","executionInfo":{"status":"ok","timestamp":1618195407117,"user_tz":240,"elapsed":24300,"user":{"displayName":"Jingkai Xu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg2sWxfWEtas0OHVeRAKACfv2J-WqEkZOHE68L3EA=s64","userId":"14485307633456209780"}},"outputId":"798a0685-c82a-4993-d1a2-d01ddf3d931a"},"source":["_, accuracy = model.evaluate(X_test, y_test)\n","print('Accuracy: %.2f' % (accuracy*100))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["46/46 [==============================] - 0s 1ms/step - loss: 0.7218 - accuracy: 0.5325\n","Accuracy: 53.25\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"SDCk3egEksaO"},"source":["# Adagrad"]},{"cell_type":"markdown","metadata":{"id":"26pXELM79gXB"},"source":["## batch 32"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8uS3qFj30CXO","executionInfo":{"status":"ok","timestamp":1618260172436,"user_tz":240,"elapsed":39979,"user":{"displayName":"Jingkai Xu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg2sWxfWEtas0OHVeRAKACfv2J-WqEkZOHE68L3EA=s64","userId":"14485307633456209780"}},"outputId":"48446be7-98cf-4d86-f60e-6f39cbc8a416"},"source":["%%time\n","tf.random.set_seed(424)\n","print(\"current days: \", num_days)\n","# define the keras model\n","model = Sequential()\n","model.add(Dense(60, input_dim=10*num_days, activation='relu'))\n","model.add(Dense(128, activation='relu'))\n","# model.add(Dense(128, activation='relu'))\n","# model.add(Dense(20, activation='relu'))\n","# model.add(Dense(1, activation='sigmoid'))\n","\n","model.add(Dense(128, activation='relu'))\n","model.add(Dense(20, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","# opt = keras.optimizers.Adam(learning_rate=0.1)\n","opt = keras.optimizers.Adagrad(\n","    learning_rate=0.1,\n","    initial_accumulator_value=0.1,\n","    epsilon=1e-07,\n","    name=\"Adagrad\"\n",")\n","\n","model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n","\n","model.fit(X_train, y_train, epochs=100,validation_split=0.1)\n","# mlp__validation_split=0.3"],"execution_count":null,"outputs":[{"output_type":"stream","text":["current days:  3\n","Epoch 1/100\n","163/163 [==============================] - 1s 4ms/step - loss: 0.6944 - accuracy: 0.5215 - val_loss: 0.6887 - val_accuracy: 0.6028\n","Epoch 2/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6892 - accuracy: 0.5391 - val_loss: 0.6855 - val_accuracy: 0.5941\n","Epoch 3/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6858 - accuracy: 0.5598 - val_loss: 0.6790 - val_accuracy: 0.5769\n","Epoch 4/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6895 - accuracy: 0.5401 - val_loss: 0.6799 - val_accuracy: 0.5924\n","Epoch 5/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6833 - accuracy: 0.5544 - val_loss: 0.6793 - val_accuracy: 0.6010\n","Epoch 6/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6868 - accuracy: 0.5545 - val_loss: 0.6848 - val_accuracy: 0.5630\n","Epoch 7/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6847 - accuracy: 0.5533 - val_loss: 0.6788 - val_accuracy: 0.5769\n","Epoch 8/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6826 - accuracy: 0.5621 - val_loss: 0.6838 - val_accuracy: 0.5458\n","Epoch 9/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6840 - accuracy: 0.5554 - val_loss: 0.6849 - val_accuracy: 0.5440\n","Epoch 10/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6835 - accuracy: 0.5467 - val_loss: 0.6780 - val_accuracy: 0.5769\n","Epoch 11/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6818 - accuracy: 0.5551 - val_loss: 0.6834 - val_accuracy: 0.5423\n","Epoch 12/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6817 - accuracy: 0.5693 - val_loss: 0.6790 - val_accuracy: 0.5941\n","Epoch 13/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6840 - accuracy: 0.5520 - val_loss: 0.6815 - val_accuracy: 0.5734\n","Epoch 14/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6870 - accuracy: 0.5421 - val_loss: 0.6878 - val_accuracy: 0.5285\n","Epoch 15/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6848 - accuracy: 0.5485 - val_loss: 0.6804 - val_accuracy: 0.5717\n","Epoch 16/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6808 - accuracy: 0.5677 - val_loss: 0.6804 - val_accuracy: 0.5820\n","Epoch 17/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6812 - accuracy: 0.5611 - val_loss: 0.6858 - val_accuracy: 0.5423\n","Epoch 18/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6822 - accuracy: 0.5572 - val_loss: 0.6804 - val_accuracy: 0.5665\n","Epoch 19/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6781 - accuracy: 0.5804 - val_loss: 0.6835 - val_accuracy: 0.5389\n","Epoch 20/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6782 - accuracy: 0.5731 - val_loss: 0.6832 - val_accuracy: 0.5544\n","Epoch 21/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6762 - accuracy: 0.5747 - val_loss: 0.6831 - val_accuracy: 0.5423\n","Epoch 22/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6783 - accuracy: 0.5661 - val_loss: 0.6826 - val_accuracy: 0.5371\n","Epoch 23/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6784 - accuracy: 0.5719 - val_loss: 0.6810 - val_accuracy: 0.5717\n","Epoch 24/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6737 - accuracy: 0.5796 - val_loss: 0.6800 - val_accuracy: 0.5613\n","Epoch 25/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6765 - accuracy: 0.5762 - val_loss: 0.6771 - val_accuracy: 0.5492\n","Epoch 26/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6757 - accuracy: 0.5709 - val_loss: 0.6800 - val_accuracy: 0.5682\n","Epoch 27/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6734 - accuracy: 0.5741 - val_loss: 0.6782 - val_accuracy: 0.5803\n","Epoch 28/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6690 - accuracy: 0.5907 - val_loss: 0.6867 - val_accuracy: 0.5475\n","Epoch 29/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6756 - accuracy: 0.5882 - val_loss: 0.6806 - val_accuracy: 0.5751\n","Epoch 30/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6752 - accuracy: 0.5820 - val_loss: 0.6815 - val_accuracy: 0.5648\n","Epoch 31/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6730 - accuracy: 0.5755 - val_loss: 0.6887 - val_accuracy: 0.5233\n","Epoch 32/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6742 - accuracy: 0.5729 - val_loss: 0.6799 - val_accuracy: 0.5682\n","Epoch 33/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6723 - accuracy: 0.5857 - val_loss: 0.6767 - val_accuracy: 0.5699\n","Epoch 34/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6699 - accuracy: 0.5823 - val_loss: 0.6824 - val_accuracy: 0.5596\n","Epoch 35/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6660 - accuracy: 0.5932 - val_loss: 0.6782 - val_accuracy: 0.5838\n","Epoch 36/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6704 - accuracy: 0.5896 - val_loss: 0.6778 - val_accuracy: 0.5717\n","Epoch 37/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6683 - accuracy: 0.5911 - val_loss: 0.6801 - val_accuracy: 0.5423\n","Epoch 38/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6659 - accuracy: 0.5841 - val_loss: 0.6801 - val_accuracy: 0.5872\n","Epoch 39/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6643 - accuracy: 0.5970 - val_loss: 0.6772 - val_accuracy: 0.5492\n","Epoch 40/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6680 - accuracy: 0.5849 - val_loss: 0.7004 - val_accuracy: 0.5285\n","Epoch 41/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6641 - accuracy: 0.5989 - val_loss: 0.6765 - val_accuracy: 0.5820\n","Epoch 42/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6665 - accuracy: 0.5900 - val_loss: 0.6766 - val_accuracy: 0.5769\n","Epoch 43/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6639 - accuracy: 0.5918 - val_loss: 0.6840 - val_accuracy: 0.5596\n","Epoch 44/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6634 - accuracy: 0.5902 - val_loss: 0.6738 - val_accuracy: 0.5717\n","Epoch 45/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6650 - accuracy: 0.5954 - val_loss: 0.6861 - val_accuracy: 0.5544\n","Epoch 46/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6644 - accuracy: 0.5900 - val_loss: 0.6792 - val_accuracy: 0.5786\n","Epoch 47/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6571 - accuracy: 0.5962 - val_loss: 0.6803 - val_accuracy: 0.5717\n","Epoch 48/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6545 - accuracy: 0.6040 - val_loss: 0.6717 - val_accuracy: 0.6010\n","Epoch 49/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6599 - accuracy: 0.5987 - val_loss: 0.6779 - val_accuracy: 0.5959\n","Epoch 50/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6464 - accuracy: 0.6174 - val_loss: 0.6903 - val_accuracy: 0.5371\n","Epoch 51/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6493 - accuracy: 0.6067 - val_loss: 0.6868 - val_accuracy: 0.5665\n","Epoch 52/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6553 - accuracy: 0.5991 - val_loss: 0.6774 - val_accuracy: 0.5976\n","Epoch 53/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6525 - accuracy: 0.6045 - val_loss: 0.6848 - val_accuracy: 0.5769\n","Epoch 54/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6537 - accuracy: 0.6116 - val_loss: 0.6921 - val_accuracy: 0.5820\n","Epoch 55/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6508 - accuracy: 0.6132 - val_loss: 0.6943 - val_accuracy: 0.5130\n","Epoch 56/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6499 - accuracy: 0.6085 - val_loss: 0.6956 - val_accuracy: 0.5803\n","Epoch 57/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6560 - accuracy: 0.5959 - val_loss: 0.6865 - val_accuracy: 0.5492\n","Epoch 58/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6453 - accuracy: 0.6196 - val_loss: 0.6977 - val_accuracy: 0.5699\n","Epoch 59/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6440 - accuracy: 0.6233 - val_loss: 0.6834 - val_accuracy: 0.5820\n","Epoch 60/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6435 - accuracy: 0.6142 - val_loss: 0.6854 - val_accuracy: 0.5630\n","Epoch 61/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6476 - accuracy: 0.6054 - val_loss: 0.7044 - val_accuracy: 0.5423\n","Epoch 62/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6443 - accuracy: 0.6198 - val_loss: 0.6894 - val_accuracy: 0.5648\n","Epoch 63/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6387 - accuracy: 0.6243 - val_loss: 0.6852 - val_accuracy: 0.5579\n","Epoch 64/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6364 - accuracy: 0.6290 - val_loss: 0.6871 - val_accuracy: 0.5976\n","Epoch 65/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6344 - accuracy: 0.6211 - val_loss: 0.6845 - val_accuracy: 0.5648\n","Epoch 66/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6290 - accuracy: 0.6345 - val_loss: 0.6894 - val_accuracy: 0.5682\n","Epoch 67/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.6333 - accuracy: 0.6355 - val_loss: 0.7059 - val_accuracy: 0.5751\n","Epoch 68/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6258 - accuracy: 0.6436 - val_loss: 0.6948 - val_accuracy: 0.5613\n","Epoch 69/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6239 - accuracy: 0.6419 - val_loss: 0.6963 - val_accuracy: 0.5561\n","Epoch 70/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6199 - accuracy: 0.6474 - val_loss: 0.7028 - val_accuracy: 0.5579\n","Epoch 71/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6227 - accuracy: 0.6407 - val_loss: 0.7127 - val_accuracy: 0.5458\n","Epoch 72/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6180 - accuracy: 0.6376 - val_loss: 0.7066 - val_accuracy: 0.5803\n","Epoch 73/100\n","163/163 [==============================] - 1s 3ms/step - loss: 0.6119 - accuracy: 0.6545 - val_loss: 0.7052 - val_accuracy: 0.5458\n","Epoch 74/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6053 - accuracy: 0.6441 - val_loss: 0.7172 - val_accuracy: 0.5492\n","Epoch 75/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6136 - accuracy: 0.6486 - val_loss: 0.7091 - val_accuracy: 0.5302\n","Epoch 76/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6031 - accuracy: 0.6620 - val_loss: 0.7086 - val_accuracy: 0.5509\n","Epoch 77/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6041 - accuracy: 0.6559 - val_loss: 0.7255 - val_accuracy: 0.5509\n","Epoch 78/100\n","163/163 [==============================] - 1s 3ms/step - loss: 0.6023 - accuracy: 0.6494 - val_loss: 0.7157 - val_accuracy: 0.5596\n","Epoch 79/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.6030 - accuracy: 0.6639 - val_loss: 0.7524 - val_accuracy: 0.5889\n","Epoch 80/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.5950 - accuracy: 0.6562 - val_loss: 0.7556 - val_accuracy: 0.5389\n","Epoch 81/100\n","163/163 [==============================] - 0s 3ms/step - loss: 0.5949 - accuracy: 0.6608 - val_loss: 0.7496 - val_accuracy: 0.5630\n","Epoch 82/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.5908 - accuracy: 0.6706 - val_loss: 0.7083 - val_accuracy: 0.5699\n","Epoch 83/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.5884 - accuracy: 0.6731 - val_loss: 0.7304 - val_accuracy: 0.5682\n","Epoch 84/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.5761 - accuracy: 0.6880 - val_loss: 0.7516 - val_accuracy: 0.5320\n","Epoch 85/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.5778 - accuracy: 0.6795 - val_loss: 0.7638 - val_accuracy: 0.5354\n","Epoch 86/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.5724 - accuracy: 0.6873 - val_loss: 0.7568 - val_accuracy: 0.5596\n","Epoch 87/100\n","163/163 [==============================] - 1s 3ms/step - loss: 0.5737 - accuracy: 0.6814 - val_loss: 0.7876 - val_accuracy: 0.5527\n","Epoch 88/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.5593 - accuracy: 0.6986 - val_loss: 0.7660 - val_accuracy: 0.5630\n","Epoch 89/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.5503 - accuracy: 0.7071 - val_loss: 0.7772 - val_accuracy: 0.5751\n","Epoch 90/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.5541 - accuracy: 0.7051 - val_loss: 0.7579 - val_accuracy: 0.5561\n","Epoch 91/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.5562 - accuracy: 0.6951 - val_loss: 0.7680 - val_accuracy: 0.5164\n","Epoch 92/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.5514 - accuracy: 0.7021 - val_loss: 0.8452 - val_accuracy: 0.5406\n","Epoch 93/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.5485 - accuracy: 0.6923 - val_loss: 0.7951 - val_accuracy: 0.5337\n","Epoch 94/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.5360 - accuracy: 0.7177 - val_loss: 0.7933 - val_accuracy: 0.5596\n","Epoch 95/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.5405 - accuracy: 0.7003 - val_loss: 0.7804 - val_accuracy: 0.5354\n","Epoch 96/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.5307 - accuracy: 0.7173 - val_loss: 0.8311 - val_accuracy: 0.5458\n","Epoch 97/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.5145 - accuracy: 0.7255 - val_loss: 0.8326 - val_accuracy: 0.5250\n","Epoch 98/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7387 - val_loss: 0.8227 - val_accuracy: 0.5216\n","Epoch 99/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.5112 - accuracy: 0.7277 - val_loss: 0.9082 - val_accuracy: 0.5354\n","Epoch 100/100\n","163/163 [==============================] - 0s 2ms/step - loss: 0.5149 - accuracy: 0.7236 - val_loss: 0.8237 - val_accuracy: 0.5509\n","CPU times: user 44.6 s, sys: 2.96 s, total: 47.6 s\n","Wall time: 39.7 s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rYWzdNIF0s3i","executionInfo":{"status":"ok","timestamp":1618260185587,"user_tz":240,"elapsed":536,"user":{"displayName":"Jingkai Xu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg2sWxfWEtas0OHVeRAKACfv2J-WqEkZOHE68L3EA=s64","userId":"14485307633456209780"}},"outputId":"d0a41b95-cccd-4604-d1b8-d27880c65374"},"source":["_, accuracy = model.evaluate(X_test, y_test)\n","print('Accuracy: %.2f' % (accuracy*100))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["46/46 [==============================] - 0s 1ms/step - loss: 0.9185 - accuracy: 0.5421\n","Accuracy: 54.21\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Jd5H7d9--r1W"},"source":["## batch 64"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jLOE6dfW-rWm","executionInfo":{"status":"ok","timestamp":1618195750532,"user_tz":240,"elapsed":23958,"user":{"displayName":"Jingkai Xu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg2sWxfWEtas0OHVeRAKACfv2J-WqEkZOHE68L3EA=s64","userId":"14485307633456209780"}},"outputId":"9396aad1-e01a-41fc-8466-4d11aa888909"},"source":["%%time\n","tf.random.set_seed(424)\n","print(\"current days: \", num_days)\n","# define the keras model\n","model = Sequential()\n","model.add(Dense(60, input_dim=10*num_days, activation='relu'))\n","model.add(Dense(128, activation='relu'))\n","# model.add(Dense(128, activation='relu'))\n","# model.add(Dense(20, activation='relu'))\n","# model.add(Dense(1, activation='sigmoid'))\n","\n","model.add(Dense(128, activation='relu'))\n","model.add(Dense(20, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","# opt = keras.optimizers.Adam(learning_rate=0.1)\n","opt = keras.optimizers.Adagrad(\n","    learning_rate=0.1,\n","    initial_accumulator_value=0.1,\n","    epsilon=1e-07,\n","    name=\"Adagrad\"\n",")\n","\n","model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n","\n","model.fit(X_train, y_train, epochs=100,batch_size = 64, validation_split=0.1)\n","# mlp__validation_split=0.3"],"execution_count":null,"outputs":[{"output_type":"stream","text":["current days:  3\n","Epoch 1/100\n","82/82 [==============================] - 1s 5ms/step - loss: 0.6940 - accuracy: 0.5133 - val_loss: 0.6870 - val_accuracy: 0.5820\n","Epoch 2/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6890 - accuracy: 0.5405 - val_loss: 0.6855 - val_accuracy: 0.5803\n","Epoch 3/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6858 - accuracy: 0.5616 - val_loss: 0.6806 - val_accuracy: 0.5838\n","Epoch 4/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6894 - accuracy: 0.5407 - val_loss: 0.6801 - val_accuracy: 0.6045\n","Epoch 5/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6828 - accuracy: 0.5644 - val_loss: 0.6787 - val_accuracy: 0.5993\n","Epoch 6/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6864 - accuracy: 0.5528 - val_loss: 0.6842 - val_accuracy: 0.5699\n","Epoch 7/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6852 - accuracy: 0.5555 - val_loss: 0.6792 - val_accuracy: 0.5717\n","Epoch 8/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6830 - accuracy: 0.5597 - val_loss: 0.6815 - val_accuracy: 0.5579\n","Epoch 9/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6845 - accuracy: 0.5555 - val_loss: 0.6855 - val_accuracy: 0.5406\n","Epoch 10/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6841 - accuracy: 0.5465 - val_loss: 0.6791 - val_accuracy: 0.5648\n","Epoch 11/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6829 - accuracy: 0.5655 - val_loss: 0.6890 - val_accuracy: 0.5302\n","Epoch 12/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6825 - accuracy: 0.5608 - val_loss: 0.6795 - val_accuracy: 0.5838\n","Epoch 13/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6849 - accuracy: 0.5452 - val_loss: 0.6808 - val_accuracy: 0.5820\n","Epoch 14/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6875 - accuracy: 0.5427 - val_loss: 0.6838 - val_accuracy: 0.5579\n","Epoch 15/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6847 - accuracy: 0.5481 - val_loss: 0.6835 - val_accuracy: 0.5682\n","Epoch 16/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6815 - accuracy: 0.5686 - val_loss: 0.6773 - val_accuracy: 0.5907\n","Epoch 17/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6809 - accuracy: 0.5690 - val_loss: 0.6922 - val_accuracy: 0.5199\n","Epoch 18/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6829 - accuracy: 0.5542 - val_loss: 0.6797 - val_accuracy: 0.5699\n","Epoch 19/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6791 - accuracy: 0.5750 - val_loss: 0.6813 - val_accuracy: 0.5475\n","Epoch 20/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6783 - accuracy: 0.5735 - val_loss: 0.6859 - val_accuracy: 0.5458\n","Epoch 21/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6759 - accuracy: 0.5736 - val_loss: 0.6814 - val_accuracy: 0.5440\n","Epoch 22/100\n","82/82 [==============================] - 0s 2ms/step - loss: 0.6772 - accuracy: 0.5720 - val_loss: 0.6778 - val_accuracy: 0.5786\n","Epoch 23/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6780 - accuracy: 0.5666 - val_loss: 0.6830 - val_accuracy: 0.5596\n","Epoch 24/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6746 - accuracy: 0.5784 - val_loss: 0.6787 - val_accuracy: 0.5699\n","Epoch 25/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6779 - accuracy: 0.5663 - val_loss: 0.6830 - val_accuracy: 0.5475\n","Epoch 26/100\n","82/82 [==============================] - 0s 2ms/step - loss: 0.6779 - accuracy: 0.5697 - val_loss: 0.6809 - val_accuracy: 0.5665\n","Epoch 27/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6746 - accuracy: 0.5719 - val_loss: 0.6785 - val_accuracy: 0.5699\n","Epoch 28/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6715 - accuracy: 0.5819 - val_loss: 0.6837 - val_accuracy: 0.5320\n","Epoch 29/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6751 - accuracy: 0.5850 - val_loss: 0.6781 - val_accuracy: 0.5751\n","Epoch 30/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6784 - accuracy: 0.5752 - val_loss: 0.6806 - val_accuracy: 0.5734\n","Epoch 31/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6760 - accuracy: 0.5667 - val_loss: 0.6901 - val_accuracy: 0.5043\n","Epoch 32/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6746 - accuracy: 0.5848 - val_loss: 0.6810 - val_accuracy: 0.5786\n","Epoch 33/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6742 - accuracy: 0.5870 - val_loss: 0.6771 - val_accuracy: 0.5665\n","Epoch 34/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6720 - accuracy: 0.5809 - val_loss: 0.6790 - val_accuracy: 0.5596\n","Epoch 35/100\n","82/82 [==============================] - 0s 2ms/step - loss: 0.6698 - accuracy: 0.5878 - val_loss: 0.6797 - val_accuracy: 0.5250\n","Epoch 36/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6740 - accuracy: 0.5824 - val_loss: 0.6780 - val_accuracy: 0.5613\n","Epoch 37/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6701 - accuracy: 0.5934 - val_loss: 0.6825 - val_accuracy: 0.5406\n","Epoch 38/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6712 - accuracy: 0.5749 - val_loss: 0.6754 - val_accuracy: 0.5872\n","Epoch 39/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6700 - accuracy: 0.5829 - val_loss: 0.6734 - val_accuracy: 0.5803\n","Epoch 40/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6728 - accuracy: 0.5829 - val_loss: 0.7020 - val_accuracy: 0.5095\n","Epoch 41/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6677 - accuracy: 0.5963 - val_loss: 0.6763 - val_accuracy: 0.5734\n","Epoch 42/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6691 - accuracy: 0.5890 - val_loss: 0.6760 - val_accuracy: 0.5924\n","Epoch 43/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6693 - accuracy: 0.5860 - val_loss: 0.6798 - val_accuracy: 0.5699\n","Epoch 44/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6663 - accuracy: 0.5881 - val_loss: 0.6716 - val_accuracy: 0.6062\n","Epoch 45/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6701 - accuracy: 0.5879 - val_loss: 0.6825 - val_accuracy: 0.5596\n","Epoch 46/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6691 - accuracy: 0.5815 - val_loss: 0.6793 - val_accuracy: 0.5734\n","Epoch 47/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6613 - accuracy: 0.5962 - val_loss: 0.6760 - val_accuracy: 0.5682\n","Epoch 48/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6607 - accuracy: 0.6016 - val_loss: 0.6713 - val_accuracy: 0.6045\n","Epoch 49/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6677 - accuracy: 0.5820 - val_loss: 0.6730 - val_accuracy: 0.6010\n","Epoch 50/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6554 - accuracy: 0.6134 - val_loss: 0.6921 - val_accuracy: 0.5423\n","Epoch 51/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6576 - accuracy: 0.6052 - val_loss: 0.6730 - val_accuracy: 0.5941\n","Epoch 52/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6639 - accuracy: 0.5863 - val_loss: 0.6749 - val_accuracy: 0.5907\n","Epoch 53/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6606 - accuracy: 0.5975 - val_loss: 0.6746 - val_accuracy: 0.5993\n","Epoch 54/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6602 - accuracy: 0.5989 - val_loss: 0.6785 - val_accuracy: 0.5769\n","Epoch 55/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6624 - accuracy: 0.6007 - val_loss: 0.6891 - val_accuracy: 0.5320\n","Epoch 56/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6598 - accuracy: 0.5963 - val_loss: 0.7000 - val_accuracy: 0.5579\n","Epoch 57/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6671 - accuracy: 0.5882 - val_loss: 0.6845 - val_accuracy: 0.5302\n","Epoch 58/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6585 - accuracy: 0.6005 - val_loss: 0.6807 - val_accuracy: 0.5976\n","Epoch 59/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6602 - accuracy: 0.6055 - val_loss: 0.6726 - val_accuracy: 0.5872\n","Epoch 60/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6557 - accuracy: 0.5949 - val_loss: 0.6714 - val_accuracy: 0.5855\n","Epoch 61/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6637 - accuracy: 0.6070 - val_loss: 0.7356 - val_accuracy: 0.4922\n","Epoch 62/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6595 - accuracy: 0.6030 - val_loss: 0.7001 - val_accuracy: 0.5406\n","Epoch 63/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6541 - accuracy: 0.6050 - val_loss: 0.6826 - val_accuracy: 0.5371\n","Epoch 64/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6522 - accuracy: 0.6107 - val_loss: 0.6771 - val_accuracy: 0.5630\n","Epoch 65/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6506 - accuracy: 0.6104 - val_loss: 0.6788 - val_accuracy: 0.5665\n","Epoch 66/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6460 - accuracy: 0.6198 - val_loss: 0.6851 - val_accuracy: 0.5579\n","Epoch 67/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6514 - accuracy: 0.6124 - val_loss: 0.6746 - val_accuracy: 0.5993\n","Epoch 68/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6507 - accuracy: 0.6160 - val_loss: 0.6809 - val_accuracy: 0.5527\n","Epoch 69/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6436 - accuracy: 0.6273 - val_loss: 0.6737 - val_accuracy: 0.6010\n","Epoch 70/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6431 - accuracy: 0.6191 - val_loss: 0.6954 - val_accuracy: 0.5544\n","Epoch 71/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6486 - accuracy: 0.6099 - val_loss: 0.6891 - val_accuracy: 0.5527\n","Epoch 72/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6452 - accuracy: 0.6206 - val_loss: 0.6790 - val_accuracy: 0.5648\n","Epoch 73/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6397 - accuracy: 0.6377 - val_loss: 0.6987 - val_accuracy: 0.5302\n","Epoch 74/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6399 - accuracy: 0.6224 - val_loss: 0.6846 - val_accuracy: 0.5734\n","Epoch 75/100\n","82/82 [==============================] - 0s 2ms/step - loss: 0.6378 - accuracy: 0.6225 - val_loss: 0.6912 - val_accuracy: 0.5181\n","Epoch 76/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6348 - accuracy: 0.6336 - val_loss: 0.6996 - val_accuracy: 0.5907\n","Epoch 77/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6371 - accuracy: 0.6353 - val_loss: 0.7237 - val_accuracy: 0.5389\n","Epoch 78/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6413 - accuracy: 0.6169 - val_loss: 0.6846 - val_accuracy: 0.5838\n","Epoch 79/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6376 - accuracy: 0.6259 - val_loss: 0.6893 - val_accuracy: 0.5699\n","Epoch 80/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6306 - accuracy: 0.6330 - val_loss: 0.7268 - val_accuracy: 0.5527\n","Epoch 81/100\n","82/82 [==============================] - 0s 2ms/step - loss: 0.6345 - accuracy: 0.6241 - val_loss: 0.7144 - val_accuracy: 0.5665\n","Epoch 82/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6314 - accuracy: 0.6328 - val_loss: 0.6892 - val_accuracy: 0.5579\n","Epoch 83/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6281 - accuracy: 0.6355 - val_loss: 0.6963 - val_accuracy: 0.5613\n","Epoch 84/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6222 - accuracy: 0.6427 - val_loss: 0.7027 - val_accuracy: 0.5389\n","Epoch 85/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6251 - accuracy: 0.6358 - val_loss: 0.7012 - val_accuracy: 0.5820\n","Epoch 86/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6205 - accuracy: 0.6388 - val_loss: 0.6942 - val_accuracy: 0.6045\n","Epoch 87/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6237 - accuracy: 0.6460 - val_loss: 0.7317 - val_accuracy: 0.5406\n","Epoch 88/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6156 - accuracy: 0.6527 - val_loss: 0.7533 - val_accuracy: 0.5302\n","Epoch 89/100\n","82/82 [==============================] - 0s 2ms/step - loss: 0.6110 - accuracy: 0.6576 - val_loss: 0.6909 - val_accuracy: 0.5976\n","Epoch 90/100\n","82/82 [==============================] - 0s 2ms/step - loss: 0.6135 - accuracy: 0.6610 - val_loss: 0.7062 - val_accuracy: 0.5475\n","Epoch 91/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6079 - accuracy: 0.6535 - val_loss: 0.6990 - val_accuracy: 0.5665\n","Epoch 92/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6143 - accuracy: 0.6558 - val_loss: 0.7197 - val_accuracy: 0.5371\n","Epoch 93/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6110 - accuracy: 0.6535 - val_loss: 0.7246 - val_accuracy: 0.5475\n","Epoch 94/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6002 - accuracy: 0.6714 - val_loss: 0.7026 - val_accuracy: 0.5838\n","Epoch 95/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6092 - accuracy: 0.6571 - val_loss: 0.7042 - val_accuracy: 0.5250\n","Epoch 96/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6081 - accuracy: 0.6585 - val_loss: 0.7375 - val_accuracy: 0.5544\n","Epoch 97/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.5996 - accuracy: 0.6593 - val_loss: 0.7163 - val_accuracy: 0.5596\n","Epoch 98/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6000 - accuracy: 0.6679 - val_loss: 0.7340 - val_accuracy: 0.5648\n","Epoch 99/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.5919 - accuracy: 0.6646 - val_loss: 0.7713 - val_accuracy: 0.5579\n","Epoch 100/100\n","82/82 [==============================] - 0s 3ms/step - loss: 0.6011 - accuracy: 0.6596 - val_loss: 0.6992 - val_accuracy: 0.5544\n","CPU times: user 27.1 s, sys: 1.19 s, total: 28.2 s\n","Wall time: 23.5 s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nDaAuHr0-rSK","executionInfo":{"status":"ok","timestamp":1618195750533,"user_tz":240,"elapsed":23956,"user":{"displayName":"Jingkai Xu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg2sWxfWEtas0OHVeRAKACfv2J-WqEkZOHE68L3EA=s64","userId":"14485307633456209780"}},"outputId":"fe5f6bfc-476c-4e83-ab75-678c9afd23cb"},"source":["_, accuracy = model.evaluate(X_test, y_test)\n","print('Accuracy: %.2f' % (accuracy*100))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["46/46 [==============================] - 0s 1ms/step - loss: 0.7677 - accuracy: 0.5366\n","Accuracy: 53.66\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"z-SVSeRTDDMj"},"source":["# Some other testing topics"]},{"cell_type":"markdown","metadata":{"id":"sVy2_rnjndUO"},"source":["## heavy shallow ANN"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cPfJqCA6nhNa","executionInfo":{"status":"ok","timestamp":1618261955294,"user_tz":240,"elapsed":26946,"user":{"displayName":"Jingkai Xu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg2sWxfWEtas0OHVeRAKACfv2J-WqEkZOHE68L3EA=s64","userId":"14485307633456209780"}},"outputId":"dfee66bd-9e2f-4bb4-a002-da6568b13db9"},"source":["%%time\n","tf.random.set_seed(424)\n","num_days = 3\n","print(\"current days: \", num_days)\n","# define the keras model\n","model = Sequential()\n","model.add(Dense(336, input_dim=10*num_days, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","# opt = keras.optimizers.Adam(learning_rate=0.1)\n","opt = keras.optimizers.Adagrad(\n","    learning_rate=0.1,\n","    initial_accumulator_value=0.1,\n","    epsilon=1e-07,\n","    name=\"Adagrad\"\n",")\n","\n","model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n","model.fit(X_train, y_train, epochs=100)\n","#model.fit(X_train, y_train, epochs=100,validation_split=0.1)\n","# mlp__validation_split=0.3"],"execution_count":null,"outputs":[{"output_type":"stream","text":["current days:  3\n","Epoch 1/100\n","181/181 [==============================] - 1s 1ms/step - loss: 0.6997 - accuracy: 0.5192\n","Epoch 2/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6903 - accuracy: 0.5431\n","Epoch 3/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6868 - accuracy: 0.5494\n","Epoch 4/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6847 - accuracy: 0.5521\n","Epoch 5/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6858 - accuracy: 0.5490\n","Epoch 6/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6840 - accuracy: 0.5607\n","Epoch 7/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6828 - accuracy: 0.5635\n","Epoch 8/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6853 - accuracy: 0.5511\n","Epoch 9/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6822 - accuracy: 0.5713\n","Epoch 10/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6819 - accuracy: 0.5609\n","Epoch 11/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6834 - accuracy: 0.5628\n","Epoch 12/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6829 - accuracy: 0.5620\n","Epoch 13/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6793 - accuracy: 0.5704\n","Epoch 14/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6829 - accuracy: 0.5548\n","Epoch 15/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6789 - accuracy: 0.5677\n","Epoch 16/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6810 - accuracy: 0.5733\n","Epoch 17/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6789 - accuracy: 0.5767\n","Epoch 18/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6781 - accuracy: 0.5779\n","Epoch 19/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6803 - accuracy: 0.5667\n","Epoch 20/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6791 - accuracy: 0.5666\n","Epoch 21/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6758 - accuracy: 0.5763\n","Epoch 22/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6795 - accuracy: 0.5751\n","Epoch 23/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6794 - accuracy: 0.5619\n","Epoch 24/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6807 - accuracy: 0.5636\n","Epoch 25/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6767 - accuracy: 0.5789\n","Epoch 26/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6781 - accuracy: 0.5719\n","Epoch 27/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6767 - accuracy: 0.5763\n","Epoch 28/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6749 - accuracy: 0.5752\n","Epoch 29/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6767 - accuracy: 0.5737\n","Epoch 30/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6777 - accuracy: 0.5627\n","Epoch 31/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6763 - accuracy: 0.5745\n","Epoch 32/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6706 - accuracy: 0.5852\n","Epoch 33/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6766 - accuracy: 0.5767\n","Epoch 34/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6717 - accuracy: 0.5924\n","Epoch 35/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6749 - accuracy: 0.5728\n","Epoch 36/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6754 - accuracy: 0.5739\n","Epoch 37/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6734 - accuracy: 0.5783\n","Epoch 38/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6712 - accuracy: 0.5841\n","Epoch 39/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6693 - accuracy: 0.5969\n","Epoch 40/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6735 - accuracy: 0.5777\n","Epoch 41/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6742 - accuracy: 0.5788\n","Epoch 42/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6716 - accuracy: 0.5852\n","Epoch 43/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6693 - accuracy: 0.5905\n","Epoch 44/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6765 - accuracy: 0.5767\n","Epoch 45/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6692 - accuracy: 0.5897\n","Epoch 46/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6753 - accuracy: 0.5801\n","Epoch 47/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6709 - accuracy: 0.5813\n","Epoch 48/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6738 - accuracy: 0.5809\n","Epoch 49/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6762 - accuracy: 0.5762\n","Epoch 50/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6709 - accuracy: 0.5825\n","Epoch 51/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6685 - accuracy: 0.5867\n","Epoch 52/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6676 - accuracy: 0.5992\n","Epoch 53/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6680 - accuracy: 0.5875\n","Epoch 54/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6722 - accuracy: 0.5792\n","Epoch 55/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6709 - accuracy: 0.5844\n","Epoch 56/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6714 - accuracy: 0.5864\n","Epoch 57/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6747 - accuracy: 0.5820\n","Epoch 58/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6654 - accuracy: 0.5962\n","Epoch 59/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6679 - accuracy: 0.5936\n","Epoch 60/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6709 - accuracy: 0.5871\n","Epoch 61/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6698 - accuracy: 0.5803\n","Epoch 62/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6675 - accuracy: 0.5885\n","Epoch 63/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6668 - accuracy: 0.5919\n","Epoch 64/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6671 - accuracy: 0.5926\n","Epoch 65/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6682 - accuracy: 0.5869\n","Epoch 66/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6629 - accuracy: 0.6055\n","Epoch 67/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6664 - accuracy: 0.5947\n","Epoch 68/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6621 - accuracy: 0.6115\n","Epoch 69/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6705 - accuracy: 0.5780\n","Epoch 70/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6645 - accuracy: 0.5979\n","Epoch 71/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6619 - accuracy: 0.5989\n","Epoch 72/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6631 - accuracy: 0.6020\n","Epoch 73/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6632 - accuracy: 0.5843\n","Epoch 74/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6645 - accuracy: 0.6048\n","Epoch 75/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6676 - accuracy: 0.5849\n","Epoch 76/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6639 - accuracy: 0.5940\n","Epoch 77/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6608 - accuracy: 0.6027\n","Epoch 78/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6620 - accuracy: 0.5944\n","Epoch 79/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6612 - accuracy: 0.5968\n","Epoch 80/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6592 - accuracy: 0.6092\n","Epoch 81/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6587 - accuracy: 0.6032\n","Epoch 82/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6622 - accuracy: 0.5980\n","Epoch 83/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6613 - accuracy: 0.6046\n","Epoch 84/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6656 - accuracy: 0.5889\n","Epoch 85/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6607 - accuracy: 0.5919\n","Epoch 86/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6585 - accuracy: 0.6080\n","Epoch 87/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6582 - accuracy: 0.6021\n","Epoch 88/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6603 - accuracy: 0.5982\n","Epoch 89/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6631 - accuracy: 0.5873\n","Epoch 90/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6585 - accuracy: 0.6044\n","Epoch 91/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6595 - accuracy: 0.6090\n","Epoch 92/100\n","181/181 [==============================] - 0s 1ms/step - loss: 0.6595 - accuracy: 0.5956\n","Epoch 93/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6530 - accuracy: 0.6137\n","Epoch 94/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6549 - accuracy: 0.6164\n","Epoch 95/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6570 - accuracy: 0.6170\n","Epoch 96/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6555 - accuracy: 0.6101\n","Epoch 97/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6538 - accuracy: 0.6151\n","Epoch 98/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6509 - accuracy: 0.6121\n","Epoch 99/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6585 - accuracy: 0.6048\n","Epoch 100/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6522 - accuracy: 0.6142\n","CPU times: user 29 s, sys: 2.92 s, total: 31.9 s\n","Wall time: 26.7 s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i4_RYnNwnlI2","executionInfo":{"status":"ok","timestamp":1618261963784,"user_tz":240,"elapsed":498,"user":{"displayName":"Jingkai Xu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg2sWxfWEtas0OHVeRAKACfv2J-WqEkZOHE68L3EA=s64","userId":"14485307633456209780"}},"outputId":"c9b5c5f5-d14c-4ac7-f4b4-203b3c58638a"},"source":["_, accuracy = model.evaluate(X_test, y_test)\n","print('Accuracy: %.2f' % (accuracy*100))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["46/46 [==============================] - 0s 2ms/step - loss: 0.7148 - accuracy: 0.5014\n","Accuracy: 50.14\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tS7rR_9lcany"},"source":["## Orignal paper's 10 input features model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0xa_pfr0UUgu","executionInfo":{"status":"ok","timestamp":1618198068791,"user_tz":240,"elapsed":37577,"user":{"displayName":"Jingkai Xu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg2sWxfWEtas0OHVeRAKACfv2J-WqEkZOHE68L3EA=s64","userId":"14485307633456209780"}},"outputId":"ef67dc51-172b-425f-b76c-f02e2b35c661"},"source":["# Run for the paper methodology, 10 input features\n","num_days = 1\n","new_input_x = []\n","for i in range (num_days, input_x.shape[0]+1):\n","    new_input_x.append(input_x[i-num_days: i, :].flatten())\n","new_input_x = np.array(new_input_x)\n","\n","new_input_y = input_y[num_days-1:]\n","\n","X_train, X_test, y_train, y_test = train_test_split(new_input_x, new_input_y, test_size = 0.2, random_state = 424)\n","# define the keras model\n","tf.random.set_seed(424)\n","model = Sequential()\n","\n","model.add(Dense(50, input_dim=10*num_days, activation='relu'))\n","\n","model.add(Dense(128, activation='relu'))\n","model.add(Dense(128, activation='relu'))\n","model.add(Dense(20, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","\n","opt = keras.optimizers.Adam(learning_rate=0.001)\n","# opt = keras.optimizers.Adadelta(\n","#     learning_rate=0.01, rho=0.95, epsilon=1e-07, name=\"Adadelta\"\n","#         )\n","model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n","model.fit(X_train, y_train, epochs=100)\n","# mlp__validation_split=0.3"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","181/181 [==============================] - 1s 2ms/step - loss: 0.6905 - accuracy: 0.5309\n","Epoch 2/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6878 - accuracy: 0.5396\n","Epoch 3/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6889 - accuracy: 0.5392\n","Epoch 4/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6863 - accuracy: 0.5494\n","Epoch 5/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6870 - accuracy: 0.5518\n","Epoch 6/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6843 - accuracy: 0.5636\n","Epoch 7/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6832 - accuracy: 0.5627\n","Epoch 8/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6833 - accuracy: 0.5668\n","Epoch 9/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6851 - accuracy: 0.5686\n","Epoch 10/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6861 - accuracy: 0.5512\n","Epoch 11/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6865 - accuracy: 0.5579\n","Epoch 12/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6850 - accuracy: 0.5588\n","Epoch 13/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6817 - accuracy: 0.5690\n","Epoch 14/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6833 - accuracy: 0.5614\n","Epoch 15/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6809 - accuracy: 0.5708\n","Epoch 16/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6844 - accuracy: 0.5576\n","Epoch 17/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6836 - accuracy: 0.5587\n","Epoch 18/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6811 - accuracy: 0.5720\n","Epoch 19/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6783 - accuracy: 0.5870\n","Epoch 20/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6836 - accuracy: 0.5613\n","Epoch 21/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6823 - accuracy: 0.5712\n","Epoch 22/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6798 - accuracy: 0.5704\n","Epoch 23/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6784 - accuracy: 0.5737\n","Epoch 24/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6788 - accuracy: 0.5700\n","Epoch 25/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6773 - accuracy: 0.5728\n","Epoch 26/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6786 - accuracy: 0.5692\n","Epoch 27/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6781 - accuracy: 0.5667\n","Epoch 28/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6789 - accuracy: 0.5644\n","Epoch 29/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6755 - accuracy: 0.5732\n","Epoch 30/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6771 - accuracy: 0.5716\n","Epoch 31/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6740 - accuracy: 0.5802\n","Epoch 32/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6740 - accuracy: 0.5806\n","Epoch 33/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6721 - accuracy: 0.5817\n","Epoch 34/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6681 - accuracy: 0.5914\n","Epoch 35/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6714 - accuracy: 0.5890\n","Epoch 36/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6739 - accuracy: 0.5707\n","Epoch 37/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6689 - accuracy: 0.5870\n","Epoch 38/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6709 - accuracy: 0.5816\n","Epoch 39/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6714 - accuracy: 0.5845\n","Epoch 40/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6659 - accuracy: 0.6002\n","Epoch 41/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6641 - accuracy: 0.5951\n","Epoch 42/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6639 - accuracy: 0.5927\n","Epoch 43/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6667 - accuracy: 0.5904\n","Epoch 44/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6687 - accuracy: 0.5893\n","Epoch 45/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6565 - accuracy: 0.6083\n","Epoch 46/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6593 - accuracy: 0.6041\n","Epoch 47/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6625 - accuracy: 0.6018\n","Epoch 48/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6570 - accuracy: 0.6092\n","Epoch 49/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6630 - accuracy: 0.5873\n","Epoch 50/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6631 - accuracy: 0.5945\n","Epoch 51/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6563 - accuracy: 0.6041\n","Epoch 52/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6537 - accuracy: 0.6085\n","Epoch 53/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6553 - accuracy: 0.6089\n","Epoch 54/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6570 - accuracy: 0.6028\n","Epoch 55/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6595 - accuracy: 0.5942\n","Epoch 56/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6487 - accuracy: 0.6162\n","Epoch 57/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6434 - accuracy: 0.6161\n","Epoch 58/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6455 - accuracy: 0.6204\n","Epoch 59/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6542 - accuracy: 0.6048\n","Epoch 60/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6416 - accuracy: 0.6166\n","Epoch 61/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6423 - accuracy: 0.6186\n","Epoch 62/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6452 - accuracy: 0.6196\n","Epoch 63/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6426 - accuracy: 0.6190\n","Epoch 64/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6350 - accuracy: 0.6202\n","Epoch 65/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6398 - accuracy: 0.6199\n","Epoch 66/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6317 - accuracy: 0.6249\n","Epoch 67/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6317 - accuracy: 0.6335\n","Epoch 68/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6343 - accuracy: 0.6279\n","Epoch 69/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6304 - accuracy: 0.6315\n","Epoch 70/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6254 - accuracy: 0.6369\n","Epoch 71/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6154 - accuracy: 0.6475\n","Epoch 72/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6210 - accuracy: 0.6470\n","Epoch 73/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6171 - accuracy: 0.6418\n","Epoch 74/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6168 - accuracy: 0.6420\n","Epoch 75/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6127 - accuracy: 0.6453\n","Epoch 76/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6109 - accuracy: 0.6514\n","Epoch 77/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6070 - accuracy: 0.6515\n","Epoch 78/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6056 - accuracy: 0.6586\n","Epoch 79/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6027 - accuracy: 0.6544\n","Epoch 80/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.5953 - accuracy: 0.6653\n","Epoch 81/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.6012 - accuracy: 0.6525\n","Epoch 82/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.5974 - accuracy: 0.6479\n","Epoch 83/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.5892 - accuracy: 0.6695\n","Epoch 84/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.5943 - accuracy: 0.6455\n","Epoch 85/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.5784 - accuracy: 0.6717\n","Epoch 86/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.5944 - accuracy: 0.6680\n","Epoch 87/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.5855 - accuracy: 0.6766\n","Epoch 88/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.5888 - accuracy: 0.6614\n","Epoch 89/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.5822 - accuracy: 0.6786\n","Epoch 90/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.5756 - accuracy: 0.6846\n","Epoch 91/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.5628 - accuracy: 0.6859\n","Epoch 92/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.5676 - accuracy: 0.6730\n","Epoch 93/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.5691 - accuracy: 0.6710\n","Epoch 94/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.5669 - accuracy: 0.6853\n","Epoch 95/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.5602 - accuracy: 0.6879\n","Epoch 96/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.5575 - accuracy: 0.6881\n","Epoch 97/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.5528 - accuracy: 0.6805\n","Epoch 98/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.5469 - accuracy: 0.6959\n","Epoch 99/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.5502 - accuracy: 0.6865\n","Epoch 100/100\n","181/181 [==============================] - 0s 2ms/step - loss: 0.5485 - accuracy: 0.6988\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f5c8b3461d0>"]},"metadata":{"tags":[]},"execution_count":48}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nM3JJJ96V5XU","executionInfo":{"status":"ok","timestamp":1618198069154,"user_tz":240,"elapsed":37139,"user":{"displayName":"Jingkai Xu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg2sWxfWEtas0OHVeRAKACfv2J-WqEkZOHE68L3EA=s64","userId":"14485307633456209780"}},"outputId":"cb7a25e7-43a0-42a8-8e23-66dcaddd2e11"},"source":["_, accuracy = model.evaluate(X_test, y_test)\n","print('Accuracy: %.2f' % (accuracy*100))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["46/46 [==============================] - 0s 1ms/step - loss: 0.8967 - accuracy: 0.5414\n","Accuracy: 54.14\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RhqbvugCDT0i"},"source":["## Find best number of years\n","Adagrad"]},{"cell_type":"code","metadata":{"id":"KmLPHAOhV7Tq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618197933298,"user_tz":240,"elapsed":169785,"user":{"displayName":"Jingkai Xu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg2sWxfWEtas0OHVeRAKACfv2J-WqEkZOHE68L3EA=s64","userId":"14485307633456209780"}},"outputId":"54760808-9515-4cb3-d6ce-5462922df140"},"source":["# Construct a time series input features\n","# as defined by how many prior days of input features to be used to predict today's stock movement\n","tf.random.set_seed(424)\n","for num_days in [4,5,6,7,8,9,10]:\n","\n","    new_input_x = []\n","    for i in range (num_days, input_x.shape[0]+1):\n","        new_input_x.append(input_x[i-num_days: i, :].flatten())\n","    new_input_x = np.array(new_input_x)\n","\n","    new_input_y = input_y[num_days-1:]\n","\n","    # X_train = new_input_x[:int(new_input_x.shape[0]*0.8), :]\n","    # y_train = new_input_y[:int(new_input_y.shape[0]*0.8), :]\n","    # X_test = new_input_x[int(new_input_x.shape[0]*0.8):, :]\n","    # y_test = new_input_y[int(new_input_y.shape[0]*0.8):, :]\n","\n","    # Splitting the dataset into the Training set and Test set\n","    X_train, X_test, y_train, y_test = train_test_split(new_input_x, new_input_y, test_size = 0.2, random_state = 424)\n","\n","    \n","    print(\"current days: \", num_days)\n","    # define the keras model\n","    model = Sequential()\n","    model.add(Dense(100, input_dim=10*num_days, activation='relu'))\n","    model.add(Dense(128, activation='relu'))\n","    model.add(Dense(128, activation='relu'))\n","    model.add(Dense(20, activation='relu'))\n","    model.add(Dense(1, activation='sigmoid'))\n","\n","    # opt = keras.optimizers.Adam(learning_rate=0.1)\n","    opt = keras.optimizers.Adagrad(\n","        learning_rate=0.1,\n","        initial_accumulator_value=0.1,\n","        epsilon=1e-07,\n","        name=\"Adagrad\"\n","    )\n","\n","    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n","\n","    training_history = model.fit(X_train, y_train, epochs=100, verbose=0, validation_split=0.1)\n","    \n","    _, accuracy = model.evaluate(X_test, y_test)\n","    print(training_history)\n","    print('Accuracy: %.2f' % (accuracy*100))\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["current days:  4\n","46/46 [==============================] - 0s 1ms/step - loss: 1.2638 - accuracy: 0.5328\n","<tensorflow.python.keras.callbacks.History object at 0x7f5c8bbddd90>\n","Accuracy: 53.28\n","current days:  5\n","46/46 [==============================] - 0s 1ms/step - loss: 1.4677 - accuracy: 0.5266\n","<tensorflow.python.keras.callbacks.History object at 0x7f5c8be7f350>\n","Accuracy: 52.66\n","current days:  6\n","46/46 [==============================] - 0s 1ms/step - loss: 1.6303 - accuracy: 0.5294\n","<tensorflow.python.keras.callbacks.History object at 0x7f5c8bd19550>\n","Accuracy: 52.94\n","current days:  7\n","46/46 [==============================] - 0s 1ms/step - loss: 2.2625 - accuracy: 0.5100\n","<tensorflow.python.keras.callbacks.History object at 0x7f5c8b709750>\n","Accuracy: 51.00\n","current days:  8\n","46/46 [==============================] - 0s 1ms/step - loss: 2.4121 - accuracy: 0.5121\n","<tensorflow.python.keras.callbacks.History object at 0x7f5c8ba22f10>\n","Accuracy: 51.21\n","current days:  9\n","46/46 [==============================] - 0s 1ms/step - loss: 2.8318 - accuracy: 0.5159\n","<tensorflow.python.keras.callbacks.History object at 0x7f5c8b84ebd0>\n","Accuracy: 51.59\n","current days:  10\n","46/46 [==============================] - 0s 1ms/step - loss: 2.2259 - accuracy: 0.5097\n","<tensorflow.python.keras.callbacks.History object at 0x7f5c7fc39b90>\n","Accuracy: 50.97\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pHBv7tXmDeC0"},"source":[""],"execution_count":null,"outputs":[]}]}